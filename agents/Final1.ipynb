{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from agents import Agent, Runner, trace, SQLiteSession, function_tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.responses import JSONResponse, FileResponse, HTMLResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from agents.items import ToolCallOutputItem\n",
    "from mimetypes import guess_type\n",
    "from typing import Optional\n",
    "from contextlib import asynccontextmanager\n",
    "import threading\n",
    "import requests\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "from openai import OpenAI\n",
    "import subprocess\n",
    "import tempfile\n",
    "from PyPDF2 import PdfReader\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "import base64\n",
    "import csv\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "client = OpenAI()\n",
    "\n",
    "# MCP Server configurations\n",
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "playwright_params = {\n",
    "    \"command\": \"npx\",\n",
    "    \"args\": [\n",
    "        \"@playwright/mcp@latest\",\n",
    "        \"--browser\", \"chrome\",\n",
    "        \"--extension\",\n",
    "        \"--shared-browser-context\",\n",
    "    ],\n",
    "    \"env\": {\n",
    "        \"PLAYWRIGHT_MCP_EXTENSION_TOKEN\": \"CELelKTMrkrFrc4QoB_dybke36loSalmSoz69QHGiWM\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Global variables\n",
    "playwright_server = None\n",
    "web_agent = None\n",
    "file_agent = None\n",
    "\n",
    "# Storage setup\n",
    "STORAGE_ROOT = Path(os.getenv(\"STORAGE_ROOT\", \"../../storage\")).resolve()\n",
    "METADATA_FILE = STORAGE_ROOT / os.getenv(\"METADATA_FILE\", \"file_metadata.json\")\n",
    "UPLOADS_DIR = STORAGE_ROOT / \"uploads\"\n",
    "\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "UPLOADS_DIR.mkdir(exist_ok=True)\n",
    "if not METADATA_FILE.exists():\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "def load_metadata():\n",
    "    if METADATA_FILE.exists():\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data if isinstance(data, list) else []\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def save_metadata(data):\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def get_current_time():\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    return datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Web Agent Tools\n",
    "@function_tool\n",
    "def get_credentials(site_name: str):\n",
    "    \"\"\"Takes site name as input and gives username and password credentials of the site\"\"\"\n",
    "    creds = dotenv_values(\".env\")\n",
    "    username_key = f\"{site_name.upper()}_USERNAME\"\n",
    "    password_key = f\"{site_name.upper()}_PASSWORD\"\n",
    "\n",
    "    if username_key in creds and password_key in creds:\n",
    "        return creds[username_key], creds[password_key]\n",
    "    else:\n",
    "        raise ValueError(f\"Credentials for {site_name}\")\n",
    "\n",
    "@function_tool\n",
    "def wait_for_user(message: str = \"Solve CAPTCHA in the browser and press Enter to continue\"):\n",
    "    \"\"\"Pause execution until the user confirms.\"\"\"\n",
    "    print(\"Hello\")\n",
    "    time.sleep(4)\n",
    "    return \"Resumed after user solved CAPTCHA\"\n",
    "\n",
    "# File Management Tools\n",
    "@function_tool\n",
    "def update_file_tool(file_name: str, new_category: str = None, new_tag: str = None):\n",
    "    \"\"\"Updates file metadata and optionally moves file between categories.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    entry = next((m for m in metadata if m[\"name\"] == file_name), None)\n",
    "\n",
    "    if not entry:\n",
    "        return {\"error\": f\"File '{file_name}' not found in metadata.\"}\n",
    "\n",
    "    src = Path(entry[\"path\"])\n",
    "    old_category_dir = src.parent\n",
    "\n",
    "    if new_category:\n",
    "        new_category_dir = STORAGE_ROOT / new_category\n",
    "        new_category_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dst = new_category_dir / src.name\n",
    "        if dst.exists():\n",
    "            return {\"error\": f\"File already exists in destination: {dst}\"}\n",
    "\n",
    "        shutil.move(str(src), dst)\n",
    "        entry[\"path\"] = str(dst)\n",
    "        entry[\"category\"] = new_category\n",
    "\n",
    "        try:\n",
    "            if old_category_dir.exists() and not any(old_category_dir.iterdir()):\n",
    "                old_category_dir.rmdir()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete empty folder {old_category_dir}: {e}\")\n",
    "\n",
    "    if new_tag is not None:\n",
    "        entry[\"tag\"] = new_tag\n",
    "\n",
    "    entry[\"last_accessed\"] = get_current_time()\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"file\": entry[\"name\"],\n",
    "        \"new_category\": entry[\"category\"],\n",
    "        \"new_tag\": entry[\"tag\"],\n",
    "        \"path\": entry[\"path\"]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def add_file_tool(file_path: str, category: str, tag: str = None, name: str = None, overwrite: bool = False, description: str = None):\n",
    "    \"\"\"Uploads a file into STORAGE_ROOT/category/tag/ and records metadata.\"\"\"\n",
    "    src = Path(file_path).resolve()\n",
    "    if not src.exists():\n",
    "        return {\"error\": f\"File not found: {src}\"}\n",
    "\n",
    "    if tag:\n",
    "        target_dir = STORAGE_ROOT / category / tag\n",
    "    else:\n",
    "        target_dir = STORAGE_ROOT / category\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if name:\n",
    "        name = Path(name).stem\n",
    "        final_name = f\"{name}{src.suffix}\"\n",
    "    else:\n",
    "        final_name = src.name\n",
    "\n",
    "    dst = target_dir / final_name\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        base, ext = dst.stem, dst.suffix\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_name = f\"{base}_{i}{ext}\"\n",
    "            new_dst = target_dir / new_name\n",
    "            if not new_dst.exists():\n",
    "                dst = new_dst\n",
    "                final_name = new_name\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = {\n",
    "        \"name\": final_name,\n",
    "        \"path\": str(dst),\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": description if description else \"No description provided\",\n",
    "        \"last_accessed\": get_current_time(),\n",
    "    }\n",
    "    metadata.append(entry)\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"stored_file\": final_name,\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": entry[\"description\"]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def get_files_tool(name: str=None, category: str=None, tag: str=None, query: str=None):\n",
    "    \"\"\"Fetches files based on filters OR semantic query.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    results = []\n",
    "    if query:\n",
    "        for entry in metadata:\n",
    "            if query.lower() in entry.get(\"description\",\"\").lower():\n",
    "                entry[\"last_accessed\"] = datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    else:\n",
    "        for entry in metadata:\n",
    "            match = True\n",
    "            if name and entry[\"name\"] != name:\n",
    "                match = False\n",
    "            if category and entry[\"category\"] != category:\n",
    "                match = False\n",
    "            if tag and entry[\"tag\"] != tag:\n",
    "                match = False\n",
    "            if match:\n",
    "                entry[\"last_accessed\"] = datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    save_metadata(metadata)\n",
    "    return {\"files\": results}\n",
    "\n",
    "@function_tool\n",
    "def load_metadata_tool():\n",
    "    \"\"\"Returns the current metadata.json content as a list of file entries.\"\"\"\n",
    "    return load_metadata()\n",
    "\n",
    "@function_tool\n",
    "def delete_files_tool(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"Deletes files and updates metadata based on filters.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated_metadata = []\n",
    "    deleted = []\n",
    "\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "\n",
    "        if match:\n",
    "            file_path = Path(entry[\"path\"])\n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                except Exception as e:\n",
    "                    return {\"error\": f\"Could not delete {file_path}: {e}\"}\n",
    "            deleted.append(entry)\n",
    "        else:\n",
    "            updated_metadata.append(entry)\n",
    "\n",
    "    save_metadata(updated_metadata)\n",
    "\n",
    "    def cleanup_empty_folders(root: Path):\n",
    "        \"\"\"Recursively remove empty folders under root, ignoring hidden files.\"\"\"\n",
    "        for folder in sorted(root.glob(\"**/*\"), key=lambda x: len(x.parts), reverse=True):\n",
    "            if folder.is_dir():\n",
    "                if not any(f for f in folder.iterdir() if not f.name.startswith('.')):\n",
    "                    try:\n",
    "                        folder.rmdir()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    cleanup_empty_folders(STORAGE_ROOT)\n",
    "\n",
    "    return {\n",
    "        \"deleted\": [d[\"name\"] for d in deleted],\n",
    "        \"remaining_files\": [f[\"name\"] for f in updated_metadata]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def read_contents(file_path: str, max_pages: int = 20, max_chars: int = 10000):\n",
    "    \"\"\"Reads the contents of a given file and returns a text preview.\"\"\"\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        return {\"error\": f\"File not found: {file_path}\"}\n",
    "\n",
    "    text_content = \"\"\n",
    "\n",
    "    try:\n",
    "        if path.suffix.lower() == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(str(path))\n",
    "                for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                    text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                    extracted = page.extract_text()\n",
    "                    text_content += extracted if extracted else \"[No extractable text]\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PDF reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".pptx\", \".ppt\"]:\n",
    "            try:\n",
    "                text_content = \"\"\n",
    "                with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                    tmpdir_path = Path(tmpdir)\n",
    "                    pdf_path = tmpdir_path / (path.stem + \".pdf\")\n",
    "\n",
    "                    subprocess.run([\n",
    "                        \"/Applications/LibreOffice.app/Contents/MacOS/soffice\",\n",
    "                        \"--headless\",\n",
    "                        \"--convert-to\", \"pdf\",\n",
    "                        str(path),\n",
    "                        \"--outdir\", str(tmpdir_path)\n",
    "                    ], check=True)\n",
    "\n",
    "                    reader = PdfReader(str(pdf_path))\n",
    "                    for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                        text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                        text_content += page.extract_text() or \"\"\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PowerPoint PDF extraction failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                data = json.loads(path.read_text(errors=\"ignore\"))\n",
    "                text_content = json.dumps(data, indent=2)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"JSON reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".csv\":\n",
    "            try:\n",
    "                with open(path, newline=\"\", encoding=\"utf-8\", errors=\"ignore\") as csvfile:\n",
    "                    reader = csv.reader(csvfile)\n",
    "                    rows = []\n",
    "                    for i, row in enumerate(reader):\n",
    "                        if i >= max_pages:\n",
    "                            break\n",
    "                        rows.append(\", \".join(row))\n",
    "                    text_content = \"\\n\".join(rows)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"CSV reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            try:\n",
    "                with open(path, \"rb\") as img_file:\n",
    "                    img_bytes = img_file.read()\n",
    "                    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an assistant that describes images in plain language.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Describe this image:\\n[base64 image data]\\n{img_b64}\"}\n",
    "                    ],\n",
    "                    max_tokens=300\n",
    "                )\n",
    "\n",
    "                text_content = response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Image description failed: {e}\"}\n",
    "\n",
    "        else:\n",
    "            # Try to read as text file\n",
    "            try:\n",
    "                text_content = path.read_text(encoding=\"utf-8\", errors=\"ignore\")[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Text file reading failed: {e}\"}\n",
    "\n",
    "        if len(text_content) > max_chars:\n",
    "            text_content = text_content[:max_chars] + \"... [truncated]\"\n",
    "\n",
    "        return {\n",
    "            \"file_name\": path.name,\n",
    "            \"path\": str(path),\n",
    "            \"content_preview\": text_content if text_content.strip() else \"[No readable content]\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "# Create File Reader Agent\n",
    "file_reader_agent = Agent(\n",
    "    name=\"FileReaderAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file classifier. \"\n",
    "        \"1. Always read the file content using `read_contents(file_path)` and summarize it in 1-2 sentences. \"\n",
    "        \"2. Use `load_metadata_tool()` to inspect existing files' descriptions, categories, and tags. \"\n",
    "        \"3. Recommend the most appropriate **category** and **tag** for this file: \"\n",
    "        \"   - The **category** should be a broad, high-level classification (e.g., 'reference_materials', 'novels', 'reports') in snake_case, lowercase, no spaces. \"\n",
    "        \"   - The **tag** should be a more specific subtopic within that category (e.g., 'compiler_design', 'fiction', 'annual_report') in snake_case, lowercase, no spaces. \"\n",
    "        \"   - Reuse an existing category/tag if it already fits the content; create a new one only if necessary. \"\n",
    "        \"4. Only output the recommended category, tag, and 1-2 sentence description. \"\n",
    "        \"   Do not modify metadata.json directly.\"\n",
    "    ),\n",
    "    tools=[read_contents, load_metadata_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "reader_tool = file_reader_agent.as_tool(\n",
    "    tool_name=\"file_reader\",\n",
    "    tool_description=\"Reads a file, generates a short description, and suggests the most appropriate category and tag for it.\"\n",
    ")\n",
    "\n",
    "# Create File Manager Agent\n",
    "file_agent = Agent(\n",
    "    name=\"FileManagerAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file manager agent. \"\n",
    "        \"Your main responsibility is to manage files: add, update, fetch metadata, and delete files. \"\n",
    "        \"\\n\\n\"\n",
    "        \"For file additions: \"\n",
    "        \"- Always keep the original 'name' field exactly as the uploaded filename. \"\n",
    "        \"- By default, call the `file_reader` tool to get the recommended description, category, and tag. \"\n",
    "        \"- If the user explicitly provides a category and/or tag, use those values instead of calling `file_reader` for them. \"\n",
    "        \"- If the user provides a description, use it; otherwise, use the one from `file_reader`. \"\n",
    "        \"- Ensure that category and tag values are stored in snake_case (e.g., 'reference_materials', 'compiler_design'). \"\n",
    "        \"- Never invent categories, tags, or descriptions yourself. \"\n",
    "        \"\\n\\n\"\n",
    "        \"For updating or moving files: \"\n",
    "        \"- Only modify category, tag, or description if explicitly requested by the user. \"\n",
    "        \"- Do not change the filename unless explicitly instructed. \"\n",
    "        \"- Do not reclassify the file with `file_reader` unless the user requests reclassification.\"\n",
    "        \"\\n\\n\"\n",
    "        \"For fetching files: \"\n",
    "        \"- Analyze the metadata's description field to determine relevance. \"\n",
    "        \"- Return files with all metadata fields (name, category, tag, path, description). \"\n",
    "        \"- Never invent or assume content.\"\n",
    "        \"\\n\\n\"\n",
    "        \"Always ground all decisions in metadata and outputs from `file_reader`. \"\n",
    "        \"Never attempt to classify or describe files on your own.\"\n",
    "    ),\n",
    "    tools=[add_file_tool, get_files_tool, delete_files_tool, update_file_tool, reader_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# Web Agent instructions\n",
    "web_instructions = \"\"\"\n",
    "You are an autonomous browsing agent.\n",
    "\n",
    "General Browsing Instructions:\n",
    "- Use ONE browser tab/page for all navigation. Do not open multiple tabs.\n",
    "- When navigating to websites, use the full URL including https:// (e.g., https://youtube.com)\n",
    "- Wait for pages to fully load before taking actions.\n",
    "- Always accept cookies and dismiss pop-ups (e.g., click \"Accept\", \"Not Now\") when prompted.\n",
    "- Close any unnecessary modals, banners, or pop-ups that appear while browsing.\n",
    "\n",
    "Login Instructions:\n",
    "- Use the get_credentials tool to retrieve the correct username and password for the website.\n",
    "- Enter credentials in their respective fields (do not input both in the same box).\n",
    "- After filling out username and password click on login button (Button might be such as Submit, Log in, etc.).\n",
    "- If captcha is present do not click on login button. Call the 'wait_for_user' tool.\n",
    "\n",
    "Website Navigation & Search Instructions:\n",
    "- Navigate the internet autonomously to complete the users instructions.\n",
    "- If one website fails to provide the required content, try alternative approaches or websites until the task is completed.\n",
    "- Follow the users instructions precisely while searching or interacting with the website content.\n",
    "- Be specific with URLs - for YouTube, use https://www.youtube.com\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI Routing Function\n",
    "def get_routing_decision(user_input: str):\n",
    "    \"\"\"Use OpenAI API to determine which agent to route to\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "You are a routing system that decides which specialized agent should handle user requests.\n",
    "\n",
    "Classification Rules:\n",
    "- investigator: Any request involving websites, web browsing, online login, web search, scraping, or internet-based tasks\n",
    "  Examples: \"login vtop\", \"search google\", \"browse youtube\", \"scrape website\", \"check social media\"\n",
    "  \n",
    "- FileManagerAgent: Any request involving local file/folder operations \n",
    "  Examples: \"organize files\", \"delete documents\", \"move photos\", \"search local files\", file uploads\n",
    "\n",
    "Input Processing Rules:\n",
    "FOR INVESTIGATOR:\n",
    "- Extract ONLY the \"User message\" part from the input\n",
    "- Look for the line that starts with \"User message:\" and extract everything after it\n",
    "- Ignore all file metadata, uploaded files info, and system context\n",
    "\n",
    "FOR FileManagerAgent:\n",
    "- Pass the COMPLETE original input including all metadata and context\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the user's request (look for the \"User message:\" part)\n",
    "2. Determine which agent should handle it based on the classification rules\n",
    "3. Return a JSON response with exactly this format:\n",
    "{\n",
    "    \"selected_agent\": \"investigator\" or \"FileManagerAgent\",\n",
    "    \"input\": \"the appropriate input for the selected agent\"\n",
    "}\n",
    "If no user input is present default fallback value for selected_agent is FileManagerAgent and input is Store all the files.\n",
    "Make sure the User input is present in the input section of the JSON\n",
    "Always return valid JSON. Do not include any other text or explanations outside the JSON.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        routing_response = response.choices[0].message.content.strip()\n",
    "        print(routing_response)\n",
    "        return json.loads(routing_response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in routing decision: {e}\")\n",
    "        # Fallback to file agent for safety\n",
    "        return {\n",
    "            \"selected_agent\": \"FileManagerAgent\",\n",
    "            \"input\": \"Store the files\"\n",
    "        }\n",
    "\n",
    "# Main Agent Runner Function\n",
    "def run_agent_sync(user_input: str, uploaded_files: list[UploadFile] = File(None)):\n",
    "    \"\"\"Run the agent routing system using OpenAI for routing decisions\"\"\"\n",
    "    from agents import Runner\n",
    "    from agents.items import ToolCallOutputItem\n",
    "    \n",
    "    # Get routing decision from OpenAI\n",
    "    routing_decision = get_routing_decision(user_input)\n",
    "    selected_agent = routing_decision[\"selected_agent\"]\n",
    "    agent_input = routing_decision[\"input\"]\n",
    "    \n",
    "    print(f\"Routing to: {selected_agent}\")  # Debug log\n",
    "    \n",
    "    # Route to appropriate agent based on decision\n",
    "    if selected_agent == \"investigator\":\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            result = loop.run_until_complete(Runner.run(web_agent, agent_input))\n",
    "        except RuntimeError:\n",
    "            result = asyncio.run(Runner.run(web_agent, agent_input))\n",
    "    elif selected_agent == \"FileManagerAgent\":\n",
    "\n",
    "        file_paths = []\n",
    "\n",
    "        # Save uploaded files\n",
    "        if uploaded_files:\n",
    "            for uploaded_file in uploaded_files:\n",
    "                file_path = UPLOADS_DIR / Path(uploaded_file.filename).name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    shutil.copyfileobj(uploaded_file.file, f)\n",
    "                file_paths.append(file_path)\n",
    "        \n",
    "        metadata = load_metadata()\n",
    "        metadata_json = json.dumps(metadata, indent=2)\n",
    "\n",
    "        user_input = f\"Here is the current file metadata (name, category, tag, description, path):\\n{metadata_json}\\n\\n\"\n",
    "        \n",
    "        if agent_input:\n",
    "            user_input += f\"User message: {agent_input}\\n\"\n",
    "        if file_paths:\n",
    "            user_input += \"Files uploaded:\\n\" + \"\\n\".join(str(p) for p in file_paths)\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            result = loop.run_until_complete(Runner.run(file_agent, user_input))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            result = asyncio.run(Runner.run(file_agent, agent_input))\n",
    "    else:\n",
    "        return f\"Unknown agent: {selected_agent}\", []\n",
    "    \n",
    "    # Extract files to show (existing logic)\n",
    "    files_to_show = []\n",
    "    for item in result.new_items:\n",
    "        if isinstance(item, ToolCallOutputItem) and isinstance(item.output, dict):\n",
    "            if \"files\" in item.output:\n",
    "                files_to_show.extend([Path(f[\"path\"]) for f in item.output[\"files\"] if \"path\" in f])\n",
    "\n",
    "    return result.final_output, files_to_show\n",
    "\n",
    "def fetch_files_for_api(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"Fetches a file asked by the user and sends it back to him.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    results = []\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "        if match:\n",
    "            results.append(entry)\n",
    "    return {\n",
    "        \"files\": [\n",
    "            {\"name\": f[\"name\"], \"category\": f[\"category\"], \"tag\": f.get(\"tag\"), \"path\": f[\"path\"]}\n",
    "            for f in results\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Watchdog Setup\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "API_URL = \"http://127.0.0.1:8000/chat\"\n",
    "processed_files = set()\n",
    "\n",
    "def wait_for_file_ready(file_path: Path, timeout=20, poll_interval=0.5):\n",
    "    start_time = time.time()\n",
    "    last_size = -1\n",
    "    while time.time() - start_time < timeout:\n",
    "        if not file_path.exists():\n",
    "            time.sleep(poll_interval)\n",
    "            continue\n",
    "        current_size = file_path.stat().st_size\n",
    "        if current_size == last_size and current_size > 0:\n",
    "            return True\n",
    "        last_size = current_size\n",
    "        time.sleep(poll_interval)\n",
    "    return False\n",
    "\n",
    "class DownloadHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        file_path = Path(event.src_path)\n",
    "\n",
    "        if file_path.suffix in [\".crdownload\", \".part\", \".tmp\"]:\n",
    "            return\n",
    "\n",
    "        if file_path in processed_files:\n",
    "            return\n",
    "        processed_files.add(file_path)\n",
    "\n",
    "        print(f\"[NEW FILE DETECTED] {file_path}\")\n",
    "\n",
    "        if not wait_for_file_ready(file_path):\n",
    "            print(f\"Warning: File not ready: {file_path}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                files = {\"uploaded_files\": (file_path.name, f)}\n",
    "                response = requests.post(API_URL, files=files)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                resp_json = response.json()\n",
    "                print(f\"[AGENT RESPONSE] {resp_json.get('chat_reply', '')}\")\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                    print(f\"Deleted original from Downloads: {file_path}\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Warning: File already deleted: {file_path}\")\n",
    "            else:\n",
    "                print(f\"Warning: API call failed: {response.status_code} {response.text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR running agent] {e}\")\n",
    "\n",
    "def start_download_monitor():\n",
    "    if not DOWNLOADS_DIR.exists():\n",
    "        print(f\"Downloads folder not found: {DOWNLOADS_DIR}\")\n",
    "        return None\n",
    "\n",
    "    event_handler = DownloadHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, str(DOWNLOADS_DIR), recursive=False)\n",
    "    observer.start()\n",
    "    print(f\"Monitoring {DOWNLOADS_DIR} for new downloads...\")\n",
    "\n",
    "    def _keep_alive():\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(2)\n",
    "        except KeyboardInterrupt:\n",
    "            observer.stop()\n",
    "        observer.join()\n",
    "\n",
    "    thread = threading.Thread(target=_keep_alive, daemon=True)\n",
    "    thread.start()\n",
    "    return observer\n",
    "\n",
    "# FastAPI Application\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    # Startup logic\n",
    "    global playwright_server, web_agent\n",
    "    \n",
    "    playwright_server = MCPServerStdio(\n",
    "        params=playwright_params, \n",
    "        client_session_timeout_seconds=60\n",
    "    )\n",
    "    await playwright_server.connect()\n",
    "    \n",
    "    # Create the web_agent with connected MCP server\n",
    "    web_agent = Agent(\n",
    "        name=\"investigator\",\n",
    "        instructions=web_instructions, \n",
    "        model=\"gpt-5-mini\",\n",
    "        mcp_servers=[playwright_server],\n",
    "        tools=[get_credentials, wait_for_user]\n",
    "    )\n",
    "    \n",
    "    yield  # This is where the app runs\n",
    "    \n",
    "    # Shutdown logic\n",
    "    if playwright_server:\n",
    "        await playwright_server.close()\n",
    "\n",
    "app = FastAPI(title=\"File Manager Agent\", lifespan=lifespan)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],       \n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],       \n",
    "    allow_headers=[\"*\"], \n",
    ")\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat_endpoint(\n",
    "    message: Optional[str] = Form(None),\n",
    "    uploaded_files: list[UploadFile] = File(None)\n",
    "):\n",
    "    if(message==None):\n",
    "        message=\"\"\n",
    "\n",
    "    \n",
    "    file_paths = []\n",
    "    metadata = load_metadata()\n",
    "    metadata_json = json.dumps(metadata, indent=2)\n",
    "    # Save uploaded files\n",
    "    if uploaded_files:\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = UPLOADS_DIR / Path(uploaded_file.filename).name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                shutil.copyfileobj(uploaded_file.file, f)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    # Run agent\n",
    "    reply, files_to_show = run_agent_sync(message, uploaded_files)\n",
    "\n",
    "    # Prepare clickable URLs\n",
    "    files_info = []\n",
    "    for f in files_to_show:\n",
    "        meta = next((m for m in metadata if Path(m[\"path\"]) == f), None)\n",
    "        if meta:\n",
    "            category = meta.get(\"category\")\n",
    "            tag = meta.get(\"tag\")\n",
    "            files_info.append({\n",
    "                \"name\": meta[\"name\"],\n",
    "                \"category\": category,\n",
    "                \"tag\": tag,\n",
    "                \"url\": f\"/download/{meta['name']}?category={category}&tag={tag}\"\n",
    "            })\n",
    "\n",
    "    return JSONResponse({\n",
    "        \"chat_reply\": reply,\n",
    "        \"files\": files_info\n",
    "    })\n",
    "\n",
    "@app.get(\"/files\")\n",
    "def get_files():\n",
    "    try:\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return {\"files\": data}\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
    "\n",
    "@app.get(\"/download/{file_name}\")\n",
    "async def download_file(file_name: str, category: str=None, tag: str=None):\n",
    "    files = fetch_files_for_api(name=file_name, category=category, tag=tag).get(\"files\", [])\n",
    "    if not files:\n",
    "        return JSONResponse({\"error\": \"File not found\"}, status_code=404)\n",
    "    \n",
    "    file_path = Path(files[0][\"path\"])\n",
    "    if not file_path.exists():\n",
    "        return JSONResponse({\"error\": \"File not found on disk\"}, status_code=404)\n",
    "\n",
    "    return FileResponse(path=file_path, filename=files[0][\"name\"])\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def home():\n",
    "    return \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>File Manager Agent</title>\n",
    "<style>\n",
    "  body { font-family: Arial, sans-serif; padding: 20px; }\n",
    "  .chat { margin-bottom: 10px; }\n",
    "  .file-links { margin-top: 10px; }\n",
    "  .uploaded-list { margin-top: 10px; color: green; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2>ðŸ¤– File Manager Agent</h2>\n",
    "\n",
    "<form id=\"chatForm\">\n",
    "  <div class=\"chat\">\n",
    "    <label>Message:</label><br>\n",
    "    <input type=\"text\" id=\"message\" size=\"50\">\n",
    "  </div>\n",
    "  <div class=\"chat\">\n",
    "    <label>Upload Files (optional):</label><br>\n",
    "    <input type=\"file\" id=\"file\" multiple>\n",
    "  </div>\n",
    "  <button type=\"submit\">Send</button>\n",
    "</form>\n",
    "\n",
    "<h3>Uploaded Files:</h3>\n",
    "<div id=\"uploadedFiles\" class=\"uploaded-list\"></div>\n",
    "\n",
    "<h3>Reply:</h3>\n",
    "<div id=\"reply\"></div>\n",
    "\n",
    "<h3>Files:</h3>\n",
    "<div id=\"files\" class=\"file-links\"></div>\n",
    "\n",
    "<script>\n",
    "const form = document.getElementById('chatForm');\n",
    "const fileInput = document.getElementById('file');\n",
    "const uploadedFilesDiv = document.getElementById('uploadedFiles');\n",
    "\n",
    "fileInput.addEventListener('change', () => {\n",
    "  uploadedFilesDiv.innerHTML = '';\n",
    "  if (fileInput.files.length > 0) {\n",
    "    uploadedFilesDiv.innerHTML = `<strong>${fileInput.files.length} file(s) selected:</strong><br>`;\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      uploadedFilesDiv.innerHTML += `â€¢ ${fileInput.files[i].name}<br>`;\n",
    "    }\n",
    "  } else {\n",
    "    uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  }\n",
    "});\n",
    "\n",
    "form.addEventListener('submit', async (e) => {\n",
    "  e.preventDefault();\n",
    "\n",
    "  const formData = new FormData();\n",
    "  formData.append('message', document.getElementById('message').value);\n",
    "\n",
    "  if (fileInput.files.length > 0) {\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      formData.append('uploaded_files', fileInput.files[i]);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const response = await fetch('/chat', {\n",
    "    method: 'POST',\n",
    "    body: formData\n",
    "  });\n",
    "\n",
    "  const data = await response.json();\n",
    "  document.getElementById('reply').innerText = data.chat_reply;\n",
    "\n",
    "  const filesDiv = document.getElementById('files');\n",
    "  filesDiv.innerHTML = '';\n",
    "  if (data.files && data.files.length > 0) {\n",
    "    data.files.forEach(f => {\n",
    "      const link = document.createElement('a');\n",
    "      link.href = f.url;\n",
    "      link.innerText = f.name;\n",
    "      link.target = '_blank';\n",
    "      filesDiv.appendChild(link);\n",
    "      filesDiv.appendChild(document.createElement('br'));\n",
    "    });\n",
    "  }\n",
    "\n",
    "  // Clear file input, uploaded files list, and optionally text\n",
    "  fileInput.value = \"\";\n",
    "  uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  document.getElementById('message').value = \"\";\n",
    "});\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "\n",
    "# Start monitoring downloads\n",
    "observer = start_download_monitor()\n",
    "\n",
    "# Main execution\n",
    "async def main():\n",
    "    config = uvicorn.Config(app=app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d967a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
