{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740649c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "from typing import Dict\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from pptx import Presentation\n",
    "from PIL import Image \n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33814c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8dd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541be6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "groq_client = AsyncOpenAI(base_url=GROQ_BASE_URL, api_key=groq_api_key)\n",
    "llama = OpenAIChatCompletionsModel(model=\"llama-3.3-70b-versatile\", openai_client=groq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c73e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/main.py\", line 579, in run\n",
      "    server.run()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
      "    self.__step()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, function_tool, Runner\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "STORAGE_ROOT = Path(os.getenv(\"STORAGE_ROOT\", \"../../storage\")).resolve()\n",
    "METADATA_FILE = STORAGE_ROOT / os.getenv(\"METADATA_FILE\", \"file_metadata.json\")\n",
    "\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "if not METADATA_FILE.exists():\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "\n",
    "def load_metadata():\n",
    "    if METADATA_FILE.exists():\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data if isinstance(data, list) else []\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "\n",
    "def save_metadata(data):\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "def get_current_time():\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    return datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def update_last_accessed(files):\n",
    "    \"\"\"Update last accessed time for the given metadata entries.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated = False\n",
    "    for entry in metadata:\n",
    "        for f in files:\n",
    "            if entry[\"path\"] == f[\"path\"]:\n",
    "                entry[\"last_accessed\"] = get_current_time()\n",
    "                updated = True\n",
    "    if updated:\n",
    "        save_metadata(metadata)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Tools (Wrapped for the Agent)\n",
    "# -----------------------------\n",
    "\n",
    "@function_tool\n",
    "def update_file_tool(\n",
    "    file_name: str,\n",
    "    new_category: str = None,\n",
    "    new_tag: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Updates file metadata and optionally moves file between categories.\n",
    "\n",
    "    Arguments:\n",
    "    - file_name: existing stored file name\n",
    "    - new_category: if provided, moves file to this category folder\n",
    "    - new_tag: if provided, updates the file's tag\n",
    "\n",
    "    Notes:\n",
    "    - If only new_tag is given → updates tag only.\n",
    "    - If only new_category is given → moves file but keeps tag.\n",
    "    - If both given → moves file and updates tag.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = next((m for m in metadata if m[\"name\"] == file_name), None)\n",
    "\n",
    "    if not entry:\n",
    "        return {\"error\": f\"File '{file_name}' not found in metadata.\"}\n",
    "\n",
    "    src = Path(entry[\"path\"])\n",
    "    old_category_dir = src.parent  \n",
    "\n",
    "    if new_category:\n",
    "        new_category_dir = STORAGE_ROOT / new_category\n",
    "        new_category_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dst = new_category_dir / src.name\n",
    "        if dst.exists():\n",
    "            return {\"error\": f\"File already exists in destination: {dst}\"}\n",
    "\n",
    "        shutil.move(str(src), dst)\n",
    "        entry[\"path\"] = str(dst)\n",
    "        entry[\"category\"] = new_category\n",
    "\n",
    "        try:\n",
    "            if old_category_dir.exists() and not any(old_category_dir.iterdir()):\n",
    "                old_category_dir.rmdir()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete empty folder {old_category_dir}: {e}\")\n",
    "\n",
    "    # --- Handle tag update ---\n",
    "    if new_tag is not None:\n",
    "        entry[\"tag\"] = new_tag\n",
    "\n",
    "\n",
    "    entry[\"last_accessed\"] = get_current_time()\n",
    "\n",
    "\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"file\": entry[\"name\"],\n",
    "        \"new_category\": entry[\"category\"],\n",
    "        \"new_tag\": entry[\"tag\"],\n",
    "        \"path\": entry[\"path\"]\n",
    "    }\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def add_file_tool(\n",
    "    file_path: str,\n",
    "    category: str,\n",
    "    tag: str = None,\n",
    "    name: str = None,\n",
    "    overwrite: bool = False,\n",
    "    description: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Uploads a file into STORAGE_ROOT/category/tag/ (if tag provided)\n",
    "    and records metadata.\n",
    "\n",
    "    Arguments:\n",
    "    - file_path: local path of the uploaded file\n",
    "    - category: folder name inside STORAGE_ROOT\n",
    "    - tag: optional label -> will also create subfolder inside category\n",
    "    - name: optional new name for the file\n",
    "    - overwrite: whether to overwrite if a file with same name exists\n",
    "    - description: short summary of the file contents\n",
    "    \"\"\"\n",
    "    src = Path(file_path).resolve()\n",
    "    if not src.exists():\n",
    "        return {\"error\": f\"File not found: {src}\"}\n",
    "\n",
    "    if tag:\n",
    "        target_dir = STORAGE_ROOT / category / tag\n",
    "    else:\n",
    "        target_dir = STORAGE_ROOT / category\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if name:\n",
    "        name = Path(name).stem\n",
    "        final_name = f\"{name}{src.suffix}\"\n",
    "    else:\n",
    "        final_name = src.name\n",
    "\n",
    "    dst = target_dir / final_name\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        base, ext = dst.stem, dst.suffix\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_name = f\"{base}_{i}{ext}\"\n",
    "            new_dst = target_dir / new_name\n",
    "            if not new_dst.exists():\n",
    "                dst = new_dst\n",
    "                final_name = new_name\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = {\n",
    "        \"name\": final_name,\n",
    "        \"path\": str(dst),\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": description if description else \"No description provided\",\n",
    "        \"last_accessed\": get_current_time(),\n",
    "    }\n",
    "    metadata.append(entry)\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"stored_file\": final_name,\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": entry[\"description\"]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_files_tool(name: str=None, category: str=None, tag: str=None, query: str=None):\n",
    "    \"\"\"\n",
    "    Fetches files based on filters OR semantic query.\n",
    "    \"\"\"\n",
    "    metadata=load_metadata()\n",
    "    results=[]\n",
    "    if query:\n",
    "        for entry in metadata:\n",
    "            if query.lower() in entry.get(\"description\",\"\").lower():\n",
    "                entry[\"last_accessed\"]=datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    else:\n",
    "        for entry in metadata:\n",
    "            match=True\n",
    "            if name and entry[\"name\"]!=name:\n",
    "                match=False\n",
    "            if category and entry[\"category\"]!=category:\n",
    "                match=False\n",
    "            if tag and entry[\"tag\"]!=tag:\n",
    "                match=False\n",
    "            if match:\n",
    "                entry[\"last_accessed\"]=datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    save_metadata(metadata)\n",
    "    return {\"files\":results}\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def load_metadata_tool():\n",
    "    \"\"\"Returns the current metadata.json content as a list of file entries.\"\"\"\n",
    "    return load_metadata()\n",
    "\n",
    "@function_tool\n",
    "def delete_files_tool(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"\n",
    "    Deletes files and updates metadata based on filters:\n",
    "    - category only\n",
    "    - tag only\n",
    "    - name only\n",
    "    - name + category + tag\n",
    "    - tag + category\n",
    "\n",
    "    After deletion, empty folders (including tag and category folders) are removed.\n",
    "    \"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated_metadata = []\n",
    "    deleted = []\n",
    "\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "\n",
    "        if match:\n",
    "            file_path = Path(entry[\"path\"])\n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                except Exception as e:\n",
    "                    return {\"error\": f\"Could not delete {file_path}: {e}\"}\n",
    "            deleted.append(entry)\n",
    "        else:\n",
    "            updated_metadata.append(entry)\n",
    "\n",
    "    save_metadata(updated_metadata)\n",
    "\n",
    "    # --- Recursive cleanup function ---\n",
    "    def cleanup_empty_folders(root: Path):\n",
    "        \"\"\"Recursively remove empty folders under root, ignoring hidden files.\"\"\"\n",
    "        for folder in sorted(root.glob(\"**/*\"), key=lambda x: len(x.parts), reverse=True):\n",
    "            if folder.is_dir():\n",
    "                if not any(f for f in folder.iterdir() if not f.name.startswith('.')):\n",
    "                    try:\n",
    "                        folder.rmdir()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    # --- Clean from STORAGE_ROOT ---\n",
    "    cleanup_empty_folders(STORAGE_ROOT)\n",
    "\n",
    "    return {\n",
    "        \"deleted\": [d[\"name\"] for d in deleted],\n",
    "        \"remaining_files\": [f[\"name\"] for f in updated_metadata]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def read_contents(file_path: str, max_pages: int = 20, max_chars: int = 10000):\n",
    "    \"\"\"\n",
    "    Reads the contents of a given file and returns a text preview.\n",
    "\n",
    "    Supports: PDF, PowerPoint, Text, JSON, CSV, Markdown, Images (AI description).\n",
    "    \"\"\"\n",
    "\n",
    "    import base64\n",
    "    from pathlib import Path\n",
    "    from PyPDF2 import PdfReader\n",
    "    from pptx import Presentation\n",
    "    import json\n",
    "    import csv\n",
    "\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        return {\"error\": f\"File not found: {file_path}\"}\n",
    "\n",
    "    text_content = \"\"\n",
    "\n",
    "    try:\n",
    "        if path.suffix.lower() == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(str(path))\n",
    "                for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                    text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                    extracted = page.extract_text()\n",
    "                    text_content += extracted if extracted else \"[No extractable text]\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PDF reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".pptx\", \".ppt\"]:\n",
    "            try:\n",
    "                prs = Presentation(str(path))\n",
    "                for i, slide in enumerate(prs.slides[:max_pages]):\n",
    "                    text_content += f\"\\n--- Slide {i+1} ---\\n\"\n",
    "                    for shape in slide.shapes:\n",
    "                        if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                            text_content += shape.text + \"\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PowerPoint reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".txt\", \".md\"]:\n",
    "            try:\n",
    "                text_content = path.read_text(errors=\"ignore\")[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Text file reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                data = json.loads(path.read_text(errors=\"ignore\"))\n",
    "                text_content = json.dumps(data, indent=2)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"JSON reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".csv\":\n",
    "            try:\n",
    "                with open(path, newline=\"\", encoding=\"utf-8\", errors=\"ignore\") as csvfile:\n",
    "                    reader = csv.reader(csvfile)\n",
    "                    rows = []\n",
    "                    for i, row in enumerate(reader):\n",
    "                        if i >= max_pages:  \n",
    "                            break\n",
    "                        rows.append(\", \".join(row))\n",
    "                    text_content = \"\\n\".join(rows)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"CSV reading failed: {e}\"}\n",
    "\n",
    "       \n",
    "        elif path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            try:\n",
    "                with open(path, \"rb\") as img_file:\n",
    "                    img_bytes = img_file.read()\n",
    "                    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an assistant that describes images in plain language.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Describe this image:\\n[base64 image data]\\n{img_b64}\"}\n",
    "                    ],\n",
    "                    max_tokens=300\n",
    "                )\n",
    "\n",
    "                text_content = response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Image description failed: {e}\"}\n",
    "\n",
    "        if len(text_content) > max_chars:\n",
    "            text_content = text_content[:max_chars] + \"... [truncated]\"\n",
    "\n",
    "        return {\n",
    "            \"file_name\": path.name,\n",
    "            \"path\": str(path),\n",
    "            \"content_preview\": text_content if text_content.strip() else \"[No readable content]\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "# -----------------------------\n",
    "# The Agent\n",
    "# -----------------------------\n",
    "file_reader_agent = Agent(\n",
    "    name=\"FileReaderAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file classifier. \"\n",
    "        \"1. Always read the file content using `read_contents(file_path)` and summarize it in 1–2 sentences. \"\n",
    "        \"2. Use `load_metadata_tool()` to inspect existing files' descriptions, categories, and tags. \"\n",
    "        \"3. Recommend the most appropriate **category** and **tag** for this file: \"\n",
    "        \"   - The **category** should be a broad, high-level classification (e.g., 'Reference Materials', 'Novels', 'Reports'). \"\n",
    "        \"   - The **tag** should be a more specific subtopic within that category (e.g., 'Compiler Design', 'Fiction', 'Annual Report'). \"\n",
    "        \"   - Reuse an existing category/tag if it already fits the content; create a new one only if necessary. \"\n",
    "        \"4. Only output the recommended category, tag, and 1–2 sentence description. \"\n",
    "        \"   Do not modify metadata.json directly.\"\n",
    "    ),\n",
    "    tools=[read_contents, load_metadata_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "reader_tool = file_reader_agent.as_tool(\n",
    "    tool_name=\"file_reader\",\n",
    "    tool_description=\"Reads a file, generates a short description, and suggests the most appropriate category and tag for it.\"\n",
    ")\n",
    "\n",
    "file_agent = Agent(\n",
    "    name=\"FileManagerAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file manager agent. \"\n",
    "        \"Your main responsibility is to manage files: add, update, fetch metadata, and delete files. \"\n",
    "        \"\\n\\n\"\n",
    "        \"When handling file content (description, category, tag): \"\n",
    "        \"- Always use the `file_reader` tool (FileReaderAgent) to read the file and get the recommended description, category, and tag. \"\n",
    "        \"- Do not try to interpret the file content yourself. \"\n",
    "        \"- Store the returned description, category, and tag exactly as suggested by the reader agent.\"\n",
    "        \"\\n\\n\"\n",
    "        \"For file additions: \"\n",
    "        \"- Always keep the original 'name' field exactly as the uploaded filename. \"\n",
    "        \"- Use the category and tag suggested by `file_reader`. \"\n",
    "        \"- Save the 1–2 sentence description provided by `file_reader` into the metadata.\"\n",
    "        \"\\n\\n\"\n",
    "        \"For updating or moving files: \"\n",
    "        \"- Only modify category, tag, or description as explicitly requested. \"\n",
    "        \"- Do not change the filename unless explicitly instructed.\"\n",
    "        \"\\n\\n\"\n",
    "        \"For fetching files: \"\n",
    "        \"- Analyze the metadata's description field to determine relevance. \"\n",
    "        \"- Return files with all metadata fields (name, category, tag, path, description). \"\n",
    "        \"- Never invent or assume content.\"\n",
    "        \"\\n\\n\"\n",
    "        \"Always ground all decisions in metadata and outputs from `file_reader`. \"\n",
    "        \"Never attempt to classify or describe files on your own.\"\n",
    "    ),\n",
    "    tools=[add_file_tool, get_files_tool, delete_files_tool, update_file_tool, reader_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3d93e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Monitoring /Users/vishwajithp/Downloads for new downloads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in FSEventsEmitter\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/watchdog/observers/fsevents.py\", line 307, in run\n",
      "    _fsevents.add_watch(self, self.watch, self.events_callback, self.pathnames)\n",
      "RuntimeError: Cannot add watch <ObservedWatch: path='/Users/vishwajithp/Downloads', is_recursive=False> - it is already scheduled\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "API_URL = \"http://127.0.0.1:8000/chat\"\n",
    "processed_files = set()  # Track already processed files\n",
    "\n",
    "def wait_for_file_ready(file_path: Path, timeout=20, poll_interval=0.5):\n",
    "    start_time = time.time()\n",
    "    last_size = -1\n",
    "    while time.time() - start_time < timeout:\n",
    "        if not file_path.exists():\n",
    "            time.sleep(poll_interval)\n",
    "            continue\n",
    "        current_size = file_path.stat().st_size\n",
    "        if current_size == last_size and current_size > 0:\n",
    "            return True\n",
    "        last_size = current_size\n",
    "        time.sleep(poll_interval)\n",
    "    return False\n",
    "\n",
    "class DownloadHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        file_path = Path(event.src_path)\n",
    "\n",
    "        # Ignore temp files\n",
    "        if file_path.suffix in [\".crdownload\", \".part\", \".tmp\"]:\n",
    "            return\n",
    "\n",
    "        # Avoid processing the same file twice\n",
    "        if file_path in processed_files:\n",
    "            return\n",
    "        processed_files.add(file_path)\n",
    "\n",
    "        print(f\"[NEW FILE DETECTED] {file_path}\")\n",
    "\n",
    "        if not wait_for_file_ready(file_path):\n",
    "            print(f\"⚠️ File not ready: {file_path}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                files = {\"uploaded_files\": (file_path.name, f)}\n",
    "                response = requests.post(API_URL, files=files)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                resp_json = response.json()\n",
    "                print(f\"[AGENT RESPONSE] {resp_json.get('chat_reply', '')}\")\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                    print(f\"✅ Deleted original from Downloads: {file_path}\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"⚠️ File already deleted: {file_path}\")\n",
    "            else:\n",
    "                print(f\"⚠️ API call failed: {response.status_code} {response.text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR running agent] {e}\")\n",
    "\n",
    "def start_download_monitor():\n",
    "    if not DOWNLOADS_DIR.exists():\n",
    "        print(f\"Downloads folder not found: {DOWNLOADS_DIR}\")\n",
    "        return None\n",
    "\n",
    "    event_handler = DownloadHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, str(DOWNLOADS_DIR), recursive=False)\n",
    "    observer.start()\n",
    "    print(f\"🚀 Monitoring {DOWNLOADS_DIR} for new downloads...\")\n",
    "\n",
    "    def _keep_alive():\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(2)\n",
    "        except KeyboardInterrupt:\n",
    "            observer.stop()\n",
    "        observer.join()\n",
    "\n",
    "    thread = threading.Thread(target=_keep_alive, daemon=True)\n",
    "    thread.start()\n",
    "    return observer\n",
    "\n",
    "# Start monitoring\n",
    "observer = start_download_monitor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7386bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [43425]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/EH4TjzHq.pptx\n",
      "⚠️ File not ready: /Users/vishwajithp/Downloads/EH4TjzHq.pptx\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-08-08_Module-1---P2.pptx\n",
      "INFO:     127.0.0.1:58522 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "[AGENT RESPONSE] The file **\"FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-08-08_Module-1---P2.pptx\"** has been successfully uploaded with the following metadata:\n",
      "\n",
      "- **Category:** Computer Science\n",
      "- **Tag:** Compiler Design\n",
      "- **Description:** The file appears to be a module related to a Computer Science course, possibly focusing on topics like programming or system design principles.\n",
      "- **Path:** /Users/vishwajithp/storage/uploads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-08-08_Module-1---P2.pptx\n",
      "\n",
      "If you need anything else, feel free to ask!\n",
      "✅ Deleted original from Downloads: /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-08-08_Module-1---P2.pptx\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/aKmVf87S.pdf\n",
      "⚠️ File not ready: /Users/vishwajithp/Downloads/aKmVf87S.pdf\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_4th-module-complete.pdf\n",
      "INFO:     127.0.0.1:58546 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "[AGENT RESPONSE] The file has been successfully uploaded and stored under the name **FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_4th-module-complete_1.pdf** with the following details:\n",
      "\n",
      "- **Category:** Computer Science\n",
      "- **Tag:** Compiler Design\n",
      "- **Description:** This document presents Module 4 content on Intermediate Code Generation, authored by Dr. P. Baskaran, as part of the BCSE307L course in Compiler Design at Vellore Institute of Technology.\n",
      "✅ Deleted original from Downloads: /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_4th-module-complete.pdf\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/gq-TcDx4.pptx\n",
      "⚠️ File not ready: /Users/vishwajithp/Downloads/gq-TcDx4.pptx\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_3rd-module-complete.pptx\n",
      "INFO:     127.0.0.1:58568 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "[AGENT RESPONSE] The file **FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_3rd-module-complete.pptx** has been successfully uploaded and stored with the following details:\n",
      "\n",
      "- **Category:** Computer Science\n",
      "- **Tag:** Compiler Design\n",
      "- **Description:** The file likely contains completed module content for a computer science course, specifically focusing on compiler design principles, consistent with previous modules in the BCSE307L course series. \n",
      "\n",
      "If you need anything else, feel free to ask!\n",
      "✅ Deleted original from Downloads: /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE307L_00100_TH_2025-09-17_3rd-module-complete.pptx\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/3VqrdI8e.pdf\n",
      "⚠️ File not ready: /Users/vishwajithp/Downloads/3VqrdI8e.pdf\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Classical-problem-of-synchronization.pdf\n",
      "INFO:     127.0.0.1:58586 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "[AGENT RESPONSE] The file **FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Classical-problem-of-synchronization.pdf** has been successfully added to the repository with the following details:\n",
      "\n",
      "- **Category:** Computer Science\n",
      "- **Tag:** Process Synchronization\n",
      "- **Description:** This document addresses classical synchronization problems in computer science, primarily focusing on the Producer-Consumer problem using semaphores, as well as other synchronization scenarios like the Dining Philosophers and Readers-Writers problems. \n",
      "\n",
      "If you need further assistance or have more files to manage, feel free to ask!\n",
      "✅ Deleted original from Downloads: /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Classical-problem-of-synchronization.pdf\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/-VBZKyrF.pdf\n",
      "⚠️ File not ready: /Users/vishwajithp/Downloads/-VBZKyrF.pdf\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Banker's-Algorithm.pdf\n",
      "INFO:     127.0.0.1:58608 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "[AGENT RESPONSE] The file \"FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Banker's-Algorithm.pdf\" has been successfully uploaded. Here are the details:\n",
      "\n",
      "- **Name:** FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Banker's-Algorithm.pdf\n",
      "- **Category:** Computer Science\n",
      "- **Tag:** Process Synchronization\n",
      "- **Description:** The document discusses the Banker’s Algorithm, a resource allocation and deadlock avoidance algorithm used in operating systems to ensure safe resource allocation among processes. It includes essential data structures and simulation methods essential for understanding resource management.\n",
      "- **Path:** /Users/vishwajithp/storage/Computer Science/FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Banker's-Algorithm.pdf\n",
      "\n",
      "If you need any further assistance, feel free to ask!\n",
      "✅ Deleted original from Downloads: /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE303P_00100_LO_2025-09-18_Banker's-Algorithm.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Request timed out.. (request_id: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58689 - \"POST /chat HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    stream = await self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
      "    stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
      "    return await self._backend.connect_tcp(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1529, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z_/z67qkp956931m3s2bm941x8r0000gn/T/ipykernel_43425/2270536922.py\", line 112, in chat_endpoint\n",
      "    reply, files_to_show = run_agent_sync(user_input)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/z_/z67qkp956931m3s2bm941x8r0000gn/T/ipykernel_43425/2270536922.py\", line 70, in run_agent_sync\n",
      "    result = loop.run_until_complete(Runner.run(file_agent, user_input))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 295, in run\n",
      "    return await runner.run(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 547, in run\n",
      "    input_guardrail_results, turn_result = await asyncio.gather(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 1222, in _run_single_turn\n",
      "    new_response = await cls._get_new_response(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 1470, in _get_new_response\n",
      "    new_response = await model.get_response(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/models/openai_responses.py\", line 90, in get_response\n",
      "    response = await self._fetch_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/models/openai_responses.py\", line 305, in _fetch_response\n",
      "    return await self._client.responses.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/resources/responses/responses.py\", line 2259, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1547, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58775 - \"POST /chat HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [43425]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.responses import JSONResponse, FileResponse, HTMLResponse\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import asyncio\n",
    "import json\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from agents.items import ToolCallOutputItem\n",
    "from mimetypes import guess_type\n",
    "from typing import Optional\n",
    "\n",
    "nest_asyncio.apply()\n",
    "app = FastAPI(title=\"File Manager Agent\")\n",
    "\n",
    "# -----------------------------\n",
    "# STORAGE SETUP\n",
    "# -----------------------------\n",
    "STORAGE_ROOT = Path(\"../../storage\").resolve()\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "UPLOADS_DIR = STORAGE_ROOT / \"uploads\"\n",
    "UPLOADS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "METADATA_FILE = STORAGE_ROOT / \"file_metadata.json\"\n",
    "if not METADATA_FILE.exists():\n",
    "    METADATA_FILE.write_text(\"[]\")  # initialize empty metadata\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def load_metadata():\n",
    "    try:\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            return data if isinstance(data, list) else []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "def fetch_files_for_api(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"\n",
    "    Fetches a file asked by the user and sends it back to him.\n",
    "    Lightweight version for API use only.\n",
    "    \"\"\"\n",
    "    metadata=load_metadata()\n",
    "    results=[]\n",
    "    for entry in metadata:\n",
    "        match=True\n",
    "        if name and entry[\"name\"]!=name:\n",
    "            match=False\n",
    "        if category and entry[\"category\"]!=category:\n",
    "            match=False\n",
    "        if tag and entry[\"tag\"]!=tag:\n",
    "            match=False\n",
    "        if match:\n",
    "            results.append(entry)\n",
    "    return {\n",
    "        \"files\":[\n",
    "            {\"name\":f[\"name\"],\"category\":f[\"category\"],\"tag\":f.get(\"tag\"),\"path\":f[\"path\"]}\n",
    "            for f in results\n",
    "        ]\n",
    "    }\n",
    "# -----------------------------\n",
    "# Agent runner (async-safe)\n",
    "# -----------------------------\n",
    "def run_agent_sync(user_input: str):\n",
    "    \"\"\"Run the agent in a sync context safely\"\"\"\n",
    "    from agents import Runner\n",
    "\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        result = loop.run_until_complete(Runner.run(file_agent, user_input))\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(Runner.run(file_agent, user_input))\n",
    "\n",
    "    files_to_show = []\n",
    "    for item in result.new_items:\n",
    "        if isinstance(item, ToolCallOutputItem) and isinstance(item.output, dict):\n",
    "            if \"files\" in item.output:\n",
    "                files_to_show.extend([Path(f[\"path\"]) for f in item.output[\"files\"] if \"path\" in f])\n",
    "\n",
    "    return result.final_output, files_to_show\n",
    "\n",
    "# -----------------------------\n",
    "# Chat endpoint\n",
    "# -----------------------------\n",
    "@app.post(\"/chat\")\n",
    "async def chat_endpoint(\n",
    "    message: Optional[str] = Form(None),\n",
    "    uploaded_files: list[UploadFile] = File(None)\n",
    "):\n",
    "    file_paths = []\n",
    "\n",
    "    # Save uploaded files\n",
    "    if uploaded_files:\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = UPLOADS_DIR / Path(uploaded_file.filename).name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                shutil.copyfileobj(uploaded_file.file, f)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    # Load metadata and include in prompt\n",
    "    metadata = load_metadata()\n",
    "    metadata_json = json.dumps(metadata, indent=2)\n",
    "\n",
    "    user_input = f\"Here is the current file metadata (name, category, tag, description, path):\\n{metadata_json}\\n\\n\"\n",
    "    \n",
    "    if message:\n",
    "        user_input += f\"User message: {message}\\n\"\n",
    "    if file_paths:\n",
    "        user_input += \"Files uploaded:\\n\" + \"\\n\".join(str(p) for p in file_paths)\n",
    "\n",
    "    # Run agent\n",
    "    reply, files_to_show = run_agent_sync(user_input)\n",
    "\n",
    "    # Prepare clickable URLs\n",
    "    files_info = []\n",
    "    for f in files_to_show:\n",
    "        meta = next((m for m in metadata if Path(m[\"path\"]) == f), None)\n",
    "        if meta:\n",
    "            category = meta.get(\"category\")\n",
    "            tag = meta.get(\"tag\")\n",
    "            files_info.append({\n",
    "                \"name\": meta[\"name\"],\n",
    "                \"category\": category,\n",
    "                \"tag\": tag,\n",
    "                \"url\": f\"/download/{meta['name']}?category={category}&tag={tag}\"\n",
    "            })\n",
    "\n",
    "    return JSONResponse({\n",
    "        \"chat_reply\": reply,\n",
    "        \"files\": files_info\n",
    "    })\n",
    "\n",
    "@app.get(\"/files\")\n",
    "def get_files():\n",
    "    absolute_path = \"/Users/vishwajithp/storage/file_metadata.json\"\n",
    "    try:\n",
    "        with open(absolute_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return {\"files\": data}\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
    "# -----------------------------\n",
    "# Download endpoint\n",
    "# -----------------------------\n",
    "@app.get(\"/download/{file_name}\")\n",
    "async def download_file(file_name: str, category: str=None, tag: str=None):\n",
    "    files=fetch_files_for_api(name=file_name, category=category, tag=tag).get(\"files\",[])\n",
    "    if not files:\n",
    "        return JSONResponse({\"error\":\"File not found\"}, status_code=404)\n",
    "    \n",
    "    file_path=Path(files[0][\"path\"])\n",
    "    if not file_path.exists():\n",
    "        return JSONResponse({\"error\":\"File not found on disk\"}, status_code=404)\n",
    "\n",
    "    return FileResponse(path=file_path, filename=files[0][\"name\"])\n",
    "# -----------------------------\n",
    "# Front-end\n",
    "# -----------------------------\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def home():\n",
    "    return \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>File Manager Agent</title>\n",
    "<style>\n",
    "  body { font-family: Arial, sans-serif; padding: 20px; }\n",
    "  .chat { margin-bottom: 10px; }\n",
    "  .file-links { margin-top: 10px; }\n",
    "  .uploaded-list { margin-top: 10px; color: green; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2>🤖 File Manager Agent</h2>\n",
    "\n",
    "<form id=\"chatForm\">\n",
    "  <div class=\"chat\">\n",
    "    <label>Message:</label><br>\n",
    "    <input type=\"text\" id=\"message\" size=\"50\">\n",
    "  </div>\n",
    "  <div class=\"chat\">\n",
    "    <label>Upload Files (optional):</label><br>\n",
    "    <input type=\"file\" id=\"file\" multiple>\n",
    "  </div>\n",
    "  <button type=\"submit\">Send</button>\n",
    "</form>\n",
    "\n",
    "<h3>Uploaded Files:</h3>\n",
    "<div id=\"uploadedFiles\" class=\"uploaded-list\"></div>\n",
    "\n",
    "<h3>Reply:</h3>\n",
    "<div id=\"reply\"></div>\n",
    "\n",
    "<h3>Files:</h3>\n",
    "<div id=\"files\" class=\"file-links\"></div>\n",
    "\n",
    "<script>\n",
    "const form = document.getElementById('chatForm');\n",
    "const fileInput = document.getElementById('file');\n",
    "const uploadedFilesDiv = document.getElementById('uploadedFiles');\n",
    "\n",
    "fileInput.addEventListener('change', () => {\n",
    "  uploadedFilesDiv.innerHTML = '';\n",
    "  if (fileInput.files.length > 0) {\n",
    "    uploadedFilesDiv.innerHTML = `<strong>${fileInput.files.length} file(s) selected:</strong><br>`;\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      uploadedFilesDiv.innerHTML += `• ${fileInput.files[i].name}<br>`;\n",
    "    }\n",
    "  } else {\n",
    "    uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  }\n",
    "});\n",
    "\n",
    "form.addEventListener('submit', async (e) => {\n",
    "  e.preventDefault();\n",
    "\n",
    "  const formData = new FormData();\n",
    "  formData.append('message', document.getElementById('message').value);\n",
    "\n",
    "  if (fileInput.files.length > 0) {\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      formData.append('uploaded_files', fileInput.files[i]);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const response = await fetch('/chat', {\n",
    "    method: 'POST',\n",
    "    body: formData\n",
    "  });\n",
    "\n",
    "  const data = await response.json();\n",
    "  document.getElementById('reply').innerText = data.chat_reply;\n",
    "\n",
    "  const filesDiv = document.getElementById('files');\n",
    "  filesDiv.innerHTML = '';\n",
    "  if (data.files && data.files.length > 0) {\n",
    "    data.files.forEach(f => {\n",
    "      const link = document.createElement('a');\n",
    "      link.href = f.url;\n",
    "      link.innerText = f.name;\n",
    "      link.target = '_blank';\n",
    "      filesDiv.appendChild(link);\n",
    "      filesDiv.appendChild(document.createElement('br'));\n",
    "    });\n",
    "  }\n",
    "\n",
    "  // --- Clear file input, uploaded files list, and optionally text ---\n",
    "  fileInput.value = \"\";\n",
    "  uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  document.getElementById('message').value = \"\";\n",
    "});\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Run server\n",
    "# -----------------------------\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e828a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248c1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0e474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6863b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
