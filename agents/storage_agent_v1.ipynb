{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740649c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "from typing import Dict\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33814c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8dd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541be6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "groq_client = AsyncOpenAI(base_url=GROQ_BASE_URL, api_key=groq_api_key)\n",
    "llama = OpenAIChatCompletionsModel(model=\"llama-3.3-70b-versatile\", openai_client=groq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c73e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool, Runner\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "STORAGE_ROOT = Path(os.getenv(\"STORAGE_ROOT\", \"../../storage\")).resolve()\n",
    "METADATA_FILE = STORAGE_ROOT / os.getenv(\"METADATA_FILE\", \"file_metadata.json\")\n",
    "\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "if not METADATA_FILE.exists():\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "\n",
    "def load_metadata():\n",
    "    if METADATA_FILE.exists():\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data if isinstance(data, list) else []\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "\n",
    "def save_metadata(data):\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "def get_current_time():\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    return datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def update_last_accessed(files):\n",
    "    \"\"\"Update last accessed time for the given metadata entries.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated = False\n",
    "    for entry in metadata:\n",
    "        for f in files:\n",
    "            if entry[\"path\"] == f[\"path\"]:\n",
    "                entry[\"last_accessed\"] = get_current_time()\n",
    "                updated = True\n",
    "    if updated:\n",
    "        save_metadata(metadata)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Tools (Wrapped for the Agent)\n",
    "# -----------------------------\n",
    "\n",
    "@function_tool\n",
    "def update_file_tool(\n",
    "    file_name: str,\n",
    "    new_category: str = None,\n",
    "    new_tag: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Updates file metadata and optionally moves file between categories.\n",
    "\n",
    "    Arguments:\n",
    "    - file_name: existing stored file name\n",
    "    - new_category: if provided, moves file to this category folder\n",
    "    - new_tag: if provided, updates the file's tag\n",
    "\n",
    "    Notes:\n",
    "    - If only new_tag is given → updates tag only.\n",
    "    - If only new_category is given → moves file but keeps tag.\n",
    "    - If both given → moves file and updates tag.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = next((m for m in metadata if m[\"name\"] == file_name), None)\n",
    "\n",
    "    if not entry:\n",
    "        return {\"error\": f\"File '{file_name}' not found in metadata.\"}\n",
    "\n",
    "    src = Path(entry[\"path\"])\n",
    "    old_category_dir = src.parent  \n",
    "\n",
    "    if new_category:\n",
    "        new_category_dir = STORAGE_ROOT / new_category\n",
    "        new_category_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dst = new_category_dir / src.name\n",
    "        if dst.exists():\n",
    "            return {\"error\": f\"File already exists in destination: {dst}\"}\n",
    "\n",
    "        shutil.move(str(src), dst)\n",
    "        entry[\"path\"] = str(dst)\n",
    "        entry[\"category\"] = new_category\n",
    "\n",
    "        try:\n",
    "            if old_category_dir.exists() and not any(old_category_dir.iterdir()):\n",
    "                old_category_dir.rmdir()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete empty folder {old_category_dir}: {e}\")\n",
    "\n",
    "    # --- Handle tag update ---\n",
    "    if new_tag is not None:\n",
    "        entry[\"tag\"] = new_tag\n",
    "\n",
    "\n",
    "    entry[\"last_accessed\"] = get_current_time()\n",
    "\n",
    "\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"file\": entry[\"name\"],\n",
    "        \"new_category\": entry[\"category\"],\n",
    "        \"new_tag\": entry[\"tag\"],\n",
    "        \"path\": entry[\"path\"]\n",
    "    }\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def add_file_tool(\n",
    "    file_path: str,\n",
    "    category: str,\n",
    "    tag: str = None,\n",
    "    name: str = None,\n",
    "    overwrite: bool = False,\n",
    "    description: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Uploads a file into STORAGE_ROOT/category/tag/ (if tag provided)\n",
    "    and records metadata.\n",
    "\n",
    "    Arguments:\n",
    "    - file_path: local path of the uploaded file\n",
    "    - category: folder name inside STORAGE_ROOT\n",
    "    - tag: optional label -> will also create subfolder inside category\n",
    "    - name: optional new name for the file\n",
    "    - overwrite: whether to overwrite if a file with same name exists\n",
    "    - description: short summary of the file contents\n",
    "    \"\"\"\n",
    "    src = Path(file_path).resolve()\n",
    "    if not src.exists():\n",
    "        return {\"error\": f\"File not found: {src}\"}\n",
    "\n",
    "    # If tag provided, put inside category/tag\n",
    "    if tag:\n",
    "        target_dir = STORAGE_ROOT / category / tag\n",
    "    else:\n",
    "        target_dir = STORAGE_ROOT / category\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if name:\n",
    "        name = Path(name).stem\n",
    "        final_name = f\"{name}{src.suffix}\"\n",
    "    else:\n",
    "        final_name = src.name\n",
    "\n",
    "    dst = target_dir / final_name\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        base, ext = dst.stem, dst.suffix\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_name = f\"{base}_{i}{ext}\"\n",
    "            new_dst = target_dir / new_name\n",
    "            if not new_dst.exists():\n",
    "                dst = new_dst\n",
    "                final_name = new_name\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = {\n",
    "        \"name\": final_name,\n",
    "        \"path\": str(dst),\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": description if description else \"No description provided\",\n",
    "        \"last_accessed\": get_current_time(),\n",
    "    }\n",
    "    metadata.append(entry)\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"stored_file\": final_name,\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": entry[\"description\"]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_files_tool(name: str=None, category: str=None, tag: str=None, query: str=None):\n",
    "    \"\"\"\n",
    "    Fetches files based on filters OR semantic query.\n",
    "    \"\"\"\n",
    "    metadata=load_metadata()\n",
    "    results=[]\n",
    "    if query:\n",
    "        for entry in metadata:\n",
    "            if query.lower() in entry.get(\"description\",\"\").lower():\n",
    "                entry[\"last_accessed\"]=datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    else:\n",
    "        for entry in metadata:\n",
    "            match=True\n",
    "            if name and entry[\"name\"]!=name:\n",
    "                match=False\n",
    "            if category and entry[\"category\"]!=category:\n",
    "                match=False\n",
    "            if tag and entry[\"tag\"]!=tag:\n",
    "                match=False\n",
    "            if match:\n",
    "                entry[\"last_accessed\"]=datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    save_metadata(metadata)\n",
    "    return {\"files\":results}\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def delete_files_tool(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"\n",
    "    Deletes files and updates metadata based on filters:\n",
    "    - category only\n",
    "    - tag only\n",
    "    - name only\n",
    "    - name + category + tag\n",
    "    - tag + category\n",
    "\n",
    "    After deletion, empty folders (including tag and category folders) are removed.\n",
    "    \"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated_metadata = []\n",
    "    deleted = []\n",
    "\n",
    "    # --- Delete matching files ---\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "\n",
    "        if match:\n",
    "            file_path = Path(entry[\"path\"])\n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                except Exception as e:\n",
    "                    return {\"error\": f\"Could not delete {file_path}: {e}\"}\n",
    "            deleted.append(entry)\n",
    "        else:\n",
    "            updated_metadata.append(entry)\n",
    "\n",
    "    save_metadata(updated_metadata)\n",
    "\n",
    "    # --- Recursive cleanup function ---\n",
    "    def cleanup_empty_folders(root: Path):\n",
    "        \"\"\"Recursively remove empty folders under root, ignoring hidden files.\"\"\"\n",
    "        # iterate bottom-up\n",
    "        for folder in sorted(root.glob(\"**/*\"), key=lambda x: len(x.parts), reverse=True):\n",
    "            if folder.is_dir():\n",
    "                # consider folder empty if no visible files/subfolders\n",
    "                if not any(f for f in folder.iterdir() if not f.name.startswith('.')):\n",
    "                    try:\n",
    "                        folder.rmdir()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    # --- Clean from STORAGE_ROOT ---\n",
    "    cleanup_empty_folders(STORAGE_ROOT)\n",
    "\n",
    "    return {\n",
    "        \"deleted\": [d[\"name\"] for d in deleted],\n",
    "        \"remaining_files\": [f[\"name\"] for f in updated_metadata]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def read_contents(file_path: str, max_pages: int = 20, max_chars: int = 10000):\n",
    "    \"\"\"\n",
    "    Reads the contents of a given file and returns a text preview.\n",
    "\n",
    "    Supports: PDF, PowerPoint, Text, JSON, CSV, Markdown, Images (AI description).\n",
    "    \"\"\"\n",
    "\n",
    "    import base64\n",
    "    from pathlib import Path\n",
    "    from PyPDF2 import PdfReader\n",
    "    from pptx import Presentation\n",
    "    import json\n",
    "    import csv\n",
    "\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        return {\"error\": f\"File not found: {file_path}\"}\n",
    "\n",
    "    text_content = \"\"\n",
    "\n",
    "    try:\n",
    "        # --- PDF ---\n",
    "        if path.suffix.lower() == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(str(path))\n",
    "                for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                    text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                    extracted = page.extract_text()\n",
    "                    text_content += extracted if extracted else \"[No extractable text]\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PDF reading failed: {e}\"}\n",
    "\n",
    "        # --- PowerPoint ---\n",
    "        elif path.suffix.lower() in [\".pptx\", \".ppt\"]:\n",
    "            try:\n",
    "                prs = Presentation(str(path))\n",
    "                for i, slide in enumerate(prs.slides[:max_pages]):\n",
    "                    text_content += f\"\\n--- Slide {i+1} ---\\n\"\n",
    "                    for shape in slide.shapes:\n",
    "                        if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                            text_content += shape.text + \"\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PowerPoint reading failed: {e}\"}\n",
    "\n",
    "        # --- Text / Markdown ---\n",
    "        elif path.suffix.lower() in [\".txt\", \".md\"]:\n",
    "            try:\n",
    "                text_content = path.read_text(errors=\"ignore\")[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Text file reading failed: {e}\"}\n",
    "\n",
    "        # --- JSON ---\n",
    "        elif path.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                data = json.loads(path.read_text(errors=\"ignore\"))\n",
    "                text_content = json.dumps(data, indent=2)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"JSON reading failed: {e}\"}\n",
    "\n",
    "        # --- CSV ---\n",
    "        elif path.suffix.lower() == \".csv\":\n",
    "            try:\n",
    "                with open(path, newline=\"\", encoding=\"utf-8\", errors=\"ignore\") as csvfile:\n",
    "                    reader = csv.reader(csvfile)\n",
    "                    rows = []\n",
    "                    for i, row in enumerate(reader):\n",
    "                        if i >= max_pages:  # treat pages as row chunks\n",
    "                            break\n",
    "                        rows.append(\", \".join(row))\n",
    "                    text_content = \"\\n\".join(rows)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"CSV reading failed: {e}\"}\n",
    "\n",
    "       \n",
    "        elif path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            try:\n",
    "                with open(path, \"rb\") as img_file:\n",
    "                    img_bytes = img_file.read()\n",
    "                    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an assistant that describes images in plain language.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Describe this image:\\n[base64 image data]\\n{img_b64}\"}\n",
    "                    ],\n",
    "                    max_tokens=300\n",
    "                )\n",
    "\n",
    "                text_content = response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Image description failed: {e}\"}\n",
    "\n",
    "\n",
    "        # --- Truncate for safety ---\n",
    "        if len(text_content) > max_chars:\n",
    "            text_content = text_content[:max_chars] + \"... [truncated]\"\n",
    "\n",
    "        return {\n",
    "            \"file_name\": path.name,\n",
    "            \"path\": str(path),\n",
    "            \"content_preview\": text_content if text_content.strip() else \"[No readable content]\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "# -----------------------------\n",
    "# The Agent\n",
    "# -----------------------------\n",
    "\n",
    "file_agent = Agent(\n",
    "    name=\"FileManagerAgent\",\n",
    "    instructions=(\n",
    "        \"You are a helpful file manager agent. \"\n",
    "        \"You strictly follow the documented tools provided. \"\n",
    "        \"You do not invent features outside these tools. \"\n",
    "        \"Always use metadata fields (name, category, tag, last_accessed, path, description) exactly as defined. \"\n",
    "        \"\\n\\n\"\n",
    "        \"Important for file additions: \"\n",
    "        \"When a new file is uploaded or added, you must always keep the 'name' field exactly as the original filename. \"\n",
    "        \"You are only allowed to modify the category, tag, and description fields. \"\n",
    "        \"\\n\\n\"\n",
    "        \"Always call the `read_contents(file_path)` tool to read the file. \"\n",
    "        \"From the extracted content, generate a **concise 1–2 sentence description of the file's actual content** \"\n",
    "        \"that can be stored in the 'description' field. \"\n",
    "        \"\\n\\n\"\n",
    "        \"If the user does not specify a category or tag, you must: \"\n",
    "        \"1. Inspect the current metadata JSON of all stored files (especially the description field). \"\n",
    "        \"2. Compare the new file's description with existing descriptions. \"\n",
    "        \"3. Choose the most appropriate category and tag based on similarity to existing files. \"\n",
    "        \"   - If an exact match is not clear, choose the closest reasonable category. \"\n",
    "        \"\\n\\n\"\n",
    "        \"Important for fetching files: \"\n",
    "        \"When a user asks for files related to a topic (e.g., 'AWS', 'compiler'), you must analyze the **description field of all stored files**. \"\n",
    "        \"Do not rely solely on tags, categories, or filenames. \"\n",
    "        \"Look into the metadata JSON dynamically and select files whose description content indicates relevance to the user's query. \"\n",
    "        \"Return all relevant files with their metadata (name, category, tag, path) without inventing information.\"\n",
    "        \"\\n\\n\"\n",
    "        \"Always ground your reasoning in the metadata and file content (via `read_contents`). \"\n",
    "        \"Never assume relevance based on partial or missing data.\"\n",
    "    ),\n",
    "    tools=[add_file_tool, get_files_tool, delete_files_tool, update_file_tool, read_contents],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd868a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Monitoring /Users/vishwajithp/Downloads for new downloads...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "\n",
    "class DownloadHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        file_path = Path(event.src_path)\n",
    "\n",
    "        # Ignore temp files (Chrome/Edge partial downloads)\n",
    "        if file_path.suffix in [\".crdownload\", \".part\"]:\n",
    "            return\n",
    "\n",
    "        print(f\"[NEW FILE DETECTED] {file_path}\")\n",
    "\n",
    "        try:\n",
    "            # Run agent (sync-safe, similar to run_agent_sync)\n",
    "            import asyncio\n",
    "            from agents.items import ToolCallOutputItem\n",
    "\n",
    "            user_input = (\n",
    "                f\"Add the file {file_path} to storage. \"\n",
    "                f\"Generate category, tag, and description automatically.\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                loop = asyncio.get_running_loop()\n",
    "                result = loop.run_until_complete(Runner.run(file_agent, user_input))\n",
    "            except RuntimeError:\n",
    "                result = asyncio.run(Runner.run(file_agent, user_input))\n",
    "\n",
    "            print(\"[AGENT RESPONSE]\", result.final_output)\n",
    "\n",
    "            # If successful, optionally delete original\n",
    "            if result.final_output and \"success\" in result.final_output.lower():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                    print(f\"✅ Deleted original from Downloads: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Could not delete {file_path}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR running agent]\", e)\n",
    "\n",
    "\n",
    "\n",
    "def start_download_monitor():\n",
    "    if not DOWNLOADS_DIR.exists():\n",
    "        print(f\"Downloads folder not found: {DOWNLOADS_DIR}\")\n",
    "        return None\n",
    "\n",
    "    event_handler = DownloadHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, str(DOWNLOADS_DIR), recursive=False)\n",
    "    observer.start()\n",
    "    print(f\"🚀 Monitoring {DOWNLOADS_DIR} for new downloads...\")\n",
    "\n",
    "    # Keep observer alive in a background thread (Jupyter-safe)\n",
    "    def _keep_alive():\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(2)\n",
    "        except KeyboardInterrupt:\n",
    "            observer.stop()\n",
    "        observer.join()\n",
    "\n",
    "    thread = threading.Thread(target=_keep_alive, daemon=True)\n",
    "    thread.start()\n",
    "\n",
    "    return observer\n",
    "\n",
    "# Start monitoring inside Jupyter\n",
    "observer = start_download_monitor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7386bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [6943]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55337 - \"GET / HTTP/1.1\" 200 OK\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/G-FZYEHR.pdf\n",
      "[ERROR running agent] There is no current event loop in thread 'Thread-4'.\n",
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE302L_00100_TH_2025-09-16_Indxing_-Hashing-and-Optimization.pdf\n",
      "[ERROR running agent] There is no current event loop in thread 'Thread-4'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/z67qkp956931m3s2bm941x8r0000gn/T/ipykernel_6943/3778975845.py:47: RuntimeWarning: coroutine 'Runner.run' was never awaited\n",
      "  print(\"[ERROR running agent]\", e)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEW FILE DETECTED] /Users/vishwajithp/Downloads/FALLSEM2025-26_VL_BCSE302L_00100_TH_2025-09-16_Indxing_-Hashing-and-Optimization.pdf\n",
      "[ERROR running agent] There is no current event loop in thread 'Thread-4'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [6943]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.responses import JSONResponse, FileResponse, HTMLResponse\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import asyncio\n",
    "import json\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from agents.items import ToolCallOutputItem\n",
    "from mimetypes import guess_type\n",
    "from typing import Optional\n",
    "\n",
    "nest_asyncio.apply()\n",
    "app = FastAPI(title=\"File Manager Agent\")\n",
    "\n",
    "# -----------------------------\n",
    "# STORAGE SETUP\n",
    "# -----------------------------\n",
    "STORAGE_ROOT = Path(\"../../storage\").resolve()\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "UPLOADS_DIR = STORAGE_ROOT / \"uploads\"\n",
    "UPLOADS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "METADATA_FILE = STORAGE_ROOT / \"file_metadata.json\"\n",
    "if not METADATA_FILE.exists():\n",
    "    METADATA_FILE.write_text(\"[]\")  # initialize empty metadata\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def load_metadata():\n",
    "    try:\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            return data if isinstance(data, list) else []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "def fetch_files_for_api(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"\n",
    "    Fetches a file asked by the user and sends it back to him.\n",
    "    Lightweight version for API use only.\n",
    "    \"\"\"\n",
    "    metadata=load_metadata()\n",
    "    results=[]\n",
    "    for entry in metadata:\n",
    "        match=True\n",
    "        if name and entry[\"name\"]!=name:\n",
    "            match=False\n",
    "        if category and entry[\"category\"]!=category:\n",
    "            match=False\n",
    "        if tag and entry[\"tag\"]!=tag:\n",
    "            match=False\n",
    "        if match:\n",
    "            results.append(entry)\n",
    "    return {\n",
    "        \"files\":[\n",
    "            {\"name\":f[\"name\"],\"category\":f[\"category\"],\"tag\":f.get(\"tag\"),\"path\":f[\"path\"]}\n",
    "            for f in results\n",
    "        ]\n",
    "    }\n",
    "# -----------------------------\n",
    "# Agent runner (async-safe)\n",
    "# -----------------------------\n",
    "def run_agent_sync(user_input: str):\n",
    "    \"\"\"Run the agent in a sync context safely\"\"\"\n",
    "    from agents import Runner\n",
    "\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        result = loop.run_until_complete(Runner.run(file_agent, user_input))\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(Runner.run(file_agent, user_input))\n",
    "\n",
    "    files_to_show = []\n",
    "    for item in result.new_items:\n",
    "        if isinstance(item, ToolCallOutputItem) and isinstance(item.output, dict):\n",
    "            if \"files\" in item.output:\n",
    "                files_to_show.extend([Path(f[\"path\"]) for f in item.output[\"files\"] if \"path\" in f])\n",
    "\n",
    "    return result.final_output, files_to_show\n",
    "\n",
    "# -----------------------------\n",
    "# Chat endpoint\n",
    "# -----------------------------\n",
    "@app.post(\"/chat\")\n",
    "async def chat_endpoint(\n",
    "    message: Optional[str] = Form(None),\n",
    "    uploaded_files: list[UploadFile] = File(None)\n",
    "):\n",
    "    file_paths = []\n",
    "\n",
    "    # Save uploaded files\n",
    "    if uploaded_files:\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = UPLOADS_DIR / Path(uploaded_file.filename).name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                shutil.copyfileobj(uploaded_file.file, f)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    # Load metadata and include in prompt\n",
    "    metadata = load_metadata()\n",
    "    metadata_json = json.dumps(metadata, indent=2)\n",
    "\n",
    "    user_input = f\"Here is the current file metadata (name, category, tag, description, path):\\n{metadata_json}\\n\\n\"\n",
    "    \n",
    "    if message:\n",
    "        user_input += f\"User message: {message}\\n\"\n",
    "    if file_paths:\n",
    "        user_input += \"Files uploaded:\\n\" + \"\\n\".join(str(p) for p in file_paths)\n",
    "\n",
    "    # Run agent\n",
    "    reply, files_to_show = run_agent_sync(user_input)\n",
    "\n",
    "    # Prepare clickable URLs\n",
    "    files_info = []\n",
    "    for f in files_to_show:\n",
    "        meta = next((m for m in metadata if Path(m[\"path\"]) == f), None)\n",
    "        if meta:\n",
    "            category = meta.get(\"category\")\n",
    "            tag = meta.get(\"tag\")\n",
    "            files_info.append({\n",
    "                \"name\": meta[\"name\"],\n",
    "                \"category\": category,\n",
    "                \"tag\": tag,\n",
    "                \"url\": f\"/download/{meta['name']}?category={category}&tag={tag}\"\n",
    "            })\n",
    "\n",
    "    return JSONResponse({\n",
    "        \"chat_reply\": reply,\n",
    "        \"files\": files_info\n",
    "    })\n",
    "\n",
    "@app.get(\"/files\")\n",
    "def get_files():\n",
    "    absolute_path = \"/home/jainaryan04/Projects/storage/file_metadata.json\"\n",
    "    try:\n",
    "        with open(absolute_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return {\"files\": data}\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
    "# -----------------------------\n",
    "# Download endpoint\n",
    "# -----------------------------\n",
    "@app.get(\"/download/{file_name}\")\n",
    "async def download_file(file_name: str, category: str=None, tag: str=None):\n",
    "    files=fetch_files_for_api(name=file_name, category=category, tag=tag).get(\"files\",[])\n",
    "    if not files:\n",
    "        return JSONResponse({\"error\":\"File not found\"}, status_code=404)\n",
    "    \n",
    "    file_path=Path(files[0][\"path\"])\n",
    "    if not file_path.exists():\n",
    "        return JSONResponse({\"error\":\"File not found on disk\"}, status_code=404)\n",
    "\n",
    "    return FileResponse(path=file_path, filename=files[0][\"name\"])\n",
    "# -----------------------------\n",
    "# Front-end\n",
    "# -----------------------------\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def home():\n",
    "    return \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>File Manager Agent</title>\n",
    "<style>\n",
    "  body { font-family: Arial, sans-serif; padding: 20px; }\n",
    "  .chat { margin-bottom: 10px; }\n",
    "  .file-links { margin-top: 10px; }\n",
    "  .uploaded-list { margin-top: 10px; color: green; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2>🤖 File Manager Agent</h2>\n",
    "\n",
    "<form id=\"chatForm\">\n",
    "  <div class=\"chat\">\n",
    "    <label>Message:</label><br>\n",
    "    <input type=\"text\" id=\"message\" size=\"50\">\n",
    "  </div>\n",
    "  <div class=\"chat\">\n",
    "    <label>Upload Files (optional):</label><br>\n",
    "    <input type=\"file\" id=\"file\" multiple>\n",
    "  </div>\n",
    "  <button type=\"submit\">Send</button>\n",
    "</form>\n",
    "\n",
    "<h3>Uploaded Files:</h3>\n",
    "<div id=\"uploadedFiles\" class=\"uploaded-list\"></div>\n",
    "\n",
    "<h3>Reply:</h3>\n",
    "<div id=\"reply\"></div>\n",
    "\n",
    "<h3>Files:</h3>\n",
    "<div id=\"files\" class=\"file-links\"></div>\n",
    "\n",
    "<script>\n",
    "const form = document.getElementById('chatForm');\n",
    "const fileInput = document.getElementById('file');\n",
    "const uploadedFilesDiv = document.getElementById('uploadedFiles');\n",
    "\n",
    "fileInput.addEventListener('change', () => {\n",
    "  uploadedFilesDiv.innerHTML = '';\n",
    "  if (fileInput.files.length > 0) {\n",
    "    uploadedFilesDiv.innerHTML = `<strong>${fileInput.files.length} file(s) selected:</strong><br>`;\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      uploadedFilesDiv.innerHTML += `• ${fileInput.files[i].name}<br>`;\n",
    "    }\n",
    "  } else {\n",
    "    uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  }\n",
    "});\n",
    "\n",
    "form.addEventListener('submit', async (e) => {\n",
    "  e.preventDefault();\n",
    "\n",
    "  const formData = new FormData();\n",
    "  formData.append('message', document.getElementById('message').value);\n",
    "\n",
    "  if (fileInput.files.length > 0) {\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      formData.append('uploaded_files', fileInput.files[i]);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const response = await fetch('/chat', {\n",
    "    method: 'POST',\n",
    "    body: formData\n",
    "  });\n",
    "\n",
    "  const data = await response.json();\n",
    "  document.getElementById('reply').innerText = data.chat_reply;\n",
    "\n",
    "  const filesDiv = document.getElementById('files');\n",
    "  filesDiv.innerHTML = '';\n",
    "  if (data.files && data.files.length > 0) {\n",
    "    data.files.forEach(f => {\n",
    "      const link = document.createElement('a');\n",
    "      link.href = f.url;\n",
    "      link.innerText = f.name;\n",
    "      link.target = '_blank';\n",
    "      filesDiv.appendChild(link);\n",
    "      filesDiv.appendChild(document.createElement('br'));\n",
    "    });\n",
    "  }\n",
    "\n",
    "  // --- Clear file input, uploaded files list, and optionally text ---\n",
    "  fileInput.value = \"\";\n",
    "  uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  document.getElementById('message').value = \"\";\n",
    "});\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Run server\n",
    "# -----------------------------\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watchdog in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248c1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0e474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
