{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd51a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in FSEventsEmitter\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/watchdog/observers/fsevents.py\", line 307, in run\n",
      "    _fsevents.add_watch(self, self.watch, self.events_callback, self.pathnames)\n",
      "RuntimeError: Cannot add watch <ObservedWatch: path='/Users/akshathr/Downloads', is_recursive=False> - it is already scheduled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring /Users/akshathr/Downloads for new downloads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [51995]\n",
      "INFO:     Waiting for application startup.\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-398' coro=<<async_generator_athrow without __name__>()> exception=RuntimeError('Attempted to exit cancel scope in a different task than it was entered in')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 188, in stdio_client\n",
      "    yield read_stream, write_stream\n",
      "GeneratorExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 815, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 188, in stdio_client\n",
      "    |     yield read_stream, write_stream\n",
      "    | GeneratorExit\n",
      "    +------------------------------------\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 181, in stdio_client\n",
      "    async with (\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 821, in __aexit__\n",
      "    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 458, in __exit__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54566 - \"GET / HTTP/1.1\" 200 OK\n",
      "{\n",
      "    \"selected_agent\": \"investigator\",\n",
      "    \"input\": \"Open youtube and search for gukesh vs magnus carlson\"\n",
      "}\n",
      "Routing to: investigator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error invoking MCP tool browser_navigate: Timed out while waiting for response to ClientRequest. Waited 60.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54588 - \"POST /chat HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/streams/memory.py\", line 111, in receive\n",
      "    return self.receive_nowait()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/streams/memory.py\", line 106, in receive_nowait\n",
      "    raise WouldBlock\n",
      "anyio.WouldBlock\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_core/_tasks.py\", line 115, in fail_after\n",
      "    yield cancel_scope\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/shared/session.py\", line 272, in send_request\n",
      "    response_or_error = await response_stream_reader.receive()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/streams/memory.py\", line 119, in receive\n",
      "    await receive_event.wait()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/futures.py\", line 198, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError: Cancelled by cancel scope 119a46950\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/shared/session.py\", line 271, in send_request\n",
      "    with anyio.fail_after(timeout):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_core/_tasks.py\", line 118, in fail_after\n",
      "    raise TimeoutError\n",
      "TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/mcp/util.py\", line 187, in invoke_mcp_tool\n",
      "    result = await server.call_tool(tool.name, json_data)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/mcp/server.py\", line 321, in call_tool\n",
      "    return await self._run_with_retries(lambda: session.call_tool(tool_name, arguments))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/mcp/server.py\", line 251, in _run_with_retries\n",
      "    return await func()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/client/session.py\", line 279, in call_tool\n",
      "    result = await self.send_request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/mcp/shared/session.py\", line 274, in send_request\n",
      "    raise McpError(\n",
      "mcp.shared.exceptions.McpError: Timed out while waiting for response to ClientRequest. Waited 60.0 seconds.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/g3/_bfwzcrs1c1fgz73qmkl8gkr0000gp/T/ipykernel_51995/1871659444.py\", line 731, in chat_endpoint\n",
      "    reply, files_to_show = run_agent_sync(user_input)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/g3/_bfwzcrs1c1fgz73qmkl8gkr0000gp/T/ipykernel_51995/1871659444.py\", line 546, in run_agent_sync\n",
      "    result = loop.run_until_complete(Runner.run(web_agent, agent_input))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 295, in run\n",
      "    return await runner.run(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 547, in run\n",
      "    input_guardrail_results, turn_result = await asyncio.gather(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 1238, in _run_single_turn\n",
      "    return await cls._get_single_step_result_from_response(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/run.py\", line 1287, in _get_single_step_result_from_response\n",
      "    return await RunImpl.execute_tools_and_side_effects(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/_run_impl.py\", line 253, in execute_tools_and_side_effects\n",
      "    function_results, computer_results = await asyncio.gather(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/_run_impl.py\", line 610, in execute_function_tool_calls\n",
      "    results = await asyncio.gather(*tasks)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/_run_impl.py\", line 598, in run_single_tool\n",
      "    raise e\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/_run_impl.py\", line 572, in run_single_tool\n",
      "    _, _, result = await asyncio.gather(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/agents/mcp/util.py\", line 190, in invoke_mcp_tool\n",
      "    raise AgentsException(f\"Error invoking MCP tool {tool.name}: {e}\") from e\n",
      "agents.exceptions.AgentsException: Error invoking MCP tool browser_navigate: Timed out while waiting for response to ClientRequest. Waited 60.0 seconds.\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "ERROR:    Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/starlette/routing.py\", line 693, in lifespan\n",
      "    async with self.lifespan_context(app) as maybe_state:\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 217, in __aexit__\n",
      "    await anext(self.gen)\n",
      "  File \"/var/folders/g3/_bfwzcrs1c1fgz73qmkl8gkr0000gp/T/ipykernel_51995/1871659444.py\", line 693, in lifespan\n",
      "    await playwright_server.close()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'MCPServerStdio' object has no attribute 'close'\n",
      "\n",
      "ERROR:    Application shutdown failed. Exiting.\n",
      "INFO:     Finished server process [51995]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 884\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m server\u001b[38;5;241m.\u001b[39mserve()\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 884\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/asyncio/events.py:84\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py:360\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[5], line 881\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    879\u001b[0m config \u001b[38;5;241m=\u001b[39m uvicorn\u001b[38;5;241m.\u001b[39mConfig(app\u001b[38;5;241m=\u001b[39mapp, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8001\u001b[39m, log_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    880\u001b[0m server \u001b[38;5;241m=\u001b[39m uvicorn\u001b[38;5;241m.\u001b[39mServer(config)\n\u001b[0;32m--> 881\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m server\u001b[38;5;241m.\u001b[39mserve()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py:69\u001b[0m, in \u001b[0;36mServer.serve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/uvicorn/server.py:330\u001b[0m, in \u001b[0;36mServer.capture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_signals):\n\u001b[0;32m--> 330\u001b[0m     signal\u001b[38;5;241m.\u001b[39mraise_signal(captured_signal)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The imports\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from agents import Agent, Runner, trace, SQLiteSession, function_tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.responses import JSONResponse, FileResponse, HTMLResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from agents.items import ToolCallOutputItem\n",
    "from mimetypes import guess_type\n",
    "from typing import Optional\n",
    "from contextlib import asynccontextmanager\n",
    "import threading\n",
    "import requests\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "from openai import OpenAI\n",
    "import subprocess\n",
    "import tempfile\n",
    "from PyPDF2 import PdfReader\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "import base64\n",
    "import csv\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "client = OpenAI()\n",
    "\n",
    "# MCP Server configurations\n",
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "playwright_params = {\n",
    "    \"command\": \"npx\",\n",
    "    \"args\": [\n",
    "        \"@playwright/mcp@latest\",\n",
    "        \"--browser\", \"chrome\",\n",
    "        \"--extension\",\n",
    "        \"--shared-browser-context\",\n",
    "    ],\n",
    "    \"env\": {\n",
    "        \"PLAYWRIGHT_MCP_EXTENSION_TOKEN\": \"kbXYnhYBBPgRZZbdQkto-L8-aTLBZQmBvPKCAmflvAk\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Global variables\n",
    "playwright_server = None\n",
    "web_agent = None\n",
    "file_agent = None\n",
    "\n",
    "# Storage setup\n",
    "STORAGE_ROOT = Path(os.getenv(\"STORAGE_ROOT\", \"../../storage\")).resolve()\n",
    "METADATA_FILE = STORAGE_ROOT / os.getenv(\"METADATA_FILE\", \"file_metadata.json\")\n",
    "UPLOADS_DIR = STORAGE_ROOT / \"uploads\"\n",
    "\n",
    "STORAGE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "UPLOADS_DIR.mkdir(exist_ok=True)\n",
    "if not METADATA_FILE.exists():\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "def load_metadata():\n",
    "    if METADATA_FILE.exists():\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data if isinstance(data, list) else []\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def save_metadata(data):\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def get_current_time():\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    return datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Web Agent Tools\n",
    "@function_tool\n",
    "def get_credentials(site_name: str):\n",
    "    \"\"\"Takes site name as input and gives username and password credentials of the site\"\"\"\n",
    "    creds = dotenv_values(\".env\")\n",
    "    username_key = f\"{site_name.upper()}_USERNAME\"\n",
    "    password_key = f\"{site_name.upper()}_PASSWORD\"\n",
    "\n",
    "    if username_key in creds and password_key in creds:\n",
    "        return creds[username_key], creds[password_key]\n",
    "    else:\n",
    "        raise ValueError(f\"Credentials for {site_name}\")\n",
    "\n",
    "@function_tool\n",
    "def wait_for_user(message: str = \"Solve CAPTCHA in the browser and press Enter to continue\"):\n",
    "    \"\"\"Pause execution until the user confirms.\"\"\"\n",
    "    print(\"Hello\")\n",
    "    time.sleep(4)\n",
    "    return \"Resumed after user solved CAPTCHA\"\n",
    "\n",
    "# File Management Tools\n",
    "@function_tool\n",
    "def update_file_tool(file_name: str, new_category: str = None, new_tag: str = None):\n",
    "    \"\"\"Updates file metadata and optionally moves file between categories.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    entry = next((m for m in metadata if m[\"name\"] == file_name), None)\n",
    "\n",
    "    if not entry:\n",
    "        return {\"error\": f\"File '{file_name}' not found in metadata.\"}\n",
    "\n",
    "    src = Path(entry[\"path\"])\n",
    "    old_category_dir = src.parent\n",
    "\n",
    "    if new_category:\n",
    "        new_category_dir = STORAGE_ROOT / new_category\n",
    "        new_category_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dst = new_category_dir / src.name\n",
    "        if dst.exists():\n",
    "            return {\"error\": f\"File already exists in destination: {dst}\"}\n",
    "\n",
    "        shutil.move(str(src), dst)\n",
    "        entry[\"path\"] = str(dst)\n",
    "        entry[\"category\"] = new_category\n",
    "\n",
    "        try:\n",
    "            if old_category_dir.exists() and not any(old_category_dir.iterdir()):\n",
    "                old_category_dir.rmdir()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete empty folder {old_category_dir}: {e}\")\n",
    "\n",
    "    if new_tag is not None:\n",
    "        entry[\"tag\"] = new_tag\n",
    "\n",
    "    entry[\"last_accessed\"] = get_current_time()\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"file\": entry[\"name\"],\n",
    "        \"new_category\": entry[\"category\"],\n",
    "        \"new_tag\": entry[\"tag\"],\n",
    "        \"path\": entry[\"path\"]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def add_file_tool(file_path: str, category: str, tag: str = None, name: str = None, overwrite: bool = False, description: str = None):\n",
    "    \"\"\"Uploads a file into STORAGE_ROOT/category/tag/ and records metadata.\"\"\"\n",
    "    src = Path(file_path).resolve()\n",
    "    if not src.exists():\n",
    "        return {\"error\": f\"File not found: {src}\"}\n",
    "\n",
    "    if tag:\n",
    "        target_dir = STORAGE_ROOT / category / tag\n",
    "    else:\n",
    "        target_dir = STORAGE_ROOT / category\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if name:\n",
    "        name = Path(name).stem\n",
    "        final_name = f\"{name}{src.suffix}\"\n",
    "    else:\n",
    "        final_name = src.name\n",
    "\n",
    "    dst = target_dir / final_name\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        base, ext = dst.stem, dst.suffix\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_name = f\"{base}_{i}{ext}\"\n",
    "            new_dst = target_dir / new_name\n",
    "            if not new_dst.exists():\n",
    "                dst = new_dst\n",
    "                final_name = new_name\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "    metadata = load_metadata()\n",
    "    entry = {\n",
    "        \"name\": final_name,\n",
    "        \"path\": str(dst),\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": description if description else \"No description provided\",\n",
    "        \"last_accessed\": get_current_time(),\n",
    "    }\n",
    "    metadata.append(entry)\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"stored_file\": final_name,\n",
    "        \"category\": category,\n",
    "        \"tag\": tag,\n",
    "        \"description\": entry[\"description\"]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def get_files_tool(name: str=None, category: str=None, tag: str=None, query: str=None):\n",
    "    \"\"\"Fetches files based on filters OR semantic query.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    results = []\n",
    "    if query:\n",
    "        for entry in metadata:\n",
    "            if query.lower() in entry.get(\"description\",\"\").lower():\n",
    "                entry[\"last_accessed\"] = datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    else:\n",
    "        for entry in metadata:\n",
    "            match = True\n",
    "            if name and entry[\"name\"] != name:\n",
    "                match = False\n",
    "            if category and entry[\"category\"] != category:\n",
    "                match = False\n",
    "            if tag and entry[\"tag\"] != tag:\n",
    "                match = False\n",
    "            if match:\n",
    "                entry[\"last_accessed\"] = datetime.now().isoformat()\n",
    "                results.append(entry)\n",
    "    save_metadata(metadata)\n",
    "    return {\"files\": results}\n",
    "\n",
    "@function_tool\n",
    "def load_metadata_tool():\n",
    "    \"\"\"Returns the current metadata.json content as a list of file entries.\"\"\"\n",
    "    return load_metadata()\n",
    "\n",
    "@function_tool\n",
    "def delete_files_tool(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"Deletes files and updates metadata based on filters.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    updated_metadata = []\n",
    "    deleted = []\n",
    "\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "\n",
    "        if match:\n",
    "            file_path = Path(entry[\"path\"])\n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                except Exception as e:\n",
    "                    return {\"error\": f\"Could not delete {file_path}: {e}\"}\n",
    "            deleted.append(entry)\n",
    "        else:\n",
    "            updated_metadata.append(entry)\n",
    "\n",
    "    save_metadata(updated_metadata)\n",
    "\n",
    "    def cleanup_empty_folders(root: Path):\n",
    "        \"\"\"Recursively remove empty folders under root, ignoring hidden files.\"\"\"\n",
    "        for folder in sorted(root.glob(\"**/*\"), key=lambda x: len(x.parts), reverse=True):\n",
    "            if folder.is_dir():\n",
    "                if not any(f for f in folder.iterdir() if not f.name.startswith('.')):\n",
    "                    try:\n",
    "                        folder.rmdir()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    cleanup_empty_folders(STORAGE_ROOT)\n",
    "\n",
    "    return {\n",
    "        \"deleted\": [d[\"name\"] for d in deleted],\n",
    "        \"remaining_files\": [f[\"name\"] for f in updated_metadata]\n",
    "    }\n",
    "\n",
    "@function_tool\n",
    "def read_contents(file_path: str, max_pages: int = 20, max_chars: int = 10000):\n",
    "    \"\"\"Reads the contents of a given file and returns a text preview.\"\"\"\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        return {\"error\": f\"File not found: {file_path}\"}\n",
    "\n",
    "    text_content = \"\"\n",
    "\n",
    "    try:\n",
    "        if path.suffix.lower() == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(str(path))\n",
    "                for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                    text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                    extracted = page.extract_text()\n",
    "                    text_content += extracted if extracted else \"[No extractable text]\\n\"\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PDF reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".pptx\", \".ppt\"]:\n",
    "            try:\n",
    "                text_content = \"\"\n",
    "                with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                    tmpdir_path = Path(tmpdir)\n",
    "                    pdf_path = tmpdir_path / (path.stem + \".pdf\")\n",
    "\n",
    "                    subprocess.run([\n",
    "                        \"/Applications/LibreOffice.app/Contents/MacOS/soffice\",\n",
    "                        \"--headless\",\n",
    "                        \"--convert-to\", \"pdf\",\n",
    "                        str(path),\n",
    "                        \"--outdir\", str(tmpdir_path)\n",
    "                    ], check=True)\n",
    "\n",
    "                    reader = PdfReader(str(pdf_path))\n",
    "                    for i, page in enumerate(reader.pages[:max_pages]):\n",
    "                        text_content += f\"\\n--- Page {i+1} ---\\n\"\n",
    "                        text_content += page.extract_text() or \"\"\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"PowerPoint PDF extraction failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                data = json.loads(path.read_text(errors=\"ignore\"))\n",
    "                text_content = json.dumps(data, indent=2)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"JSON reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() == \".csv\":\n",
    "            try:\n",
    "                with open(path, newline=\"\", encoding=\"utf-8\", errors=\"ignore\") as csvfile:\n",
    "                    reader = csv.reader(csvfile)\n",
    "                    rows = []\n",
    "                    for i, row in enumerate(reader):\n",
    "                        if i >= max_pages:\n",
    "                            break\n",
    "                        rows.append(\", \".join(row))\n",
    "                    text_content = \"\\n\".join(rows)[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"CSV reading failed: {e}\"}\n",
    "\n",
    "        elif path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            try:\n",
    "                with open(path, \"rb\") as img_file:\n",
    "                    img_bytes = img_file.read()\n",
    "                    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an assistant that describes images in plain language.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Describe this image:\\n[base64 image data]\\n{img_b64}\"}\n",
    "                    ],\n",
    "                    max_tokens=300\n",
    "                )\n",
    "\n",
    "                text_content = response.choices[0].message.content.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Image description failed: {e}\"}\n",
    "\n",
    "        else:\n",
    "            # Try to read as text file\n",
    "            try:\n",
    "                text_content = path.read_text(encoding=\"utf-8\", errors=\"ignore\")[:max_chars]\n",
    "            except Exception as e:\n",
    "                return {\"error\": f\"Text file reading failed: {e}\"}\n",
    "\n",
    "        if len(text_content) > max_chars:\n",
    "            text_content = text_content[:max_chars] + \"... [truncated]\"\n",
    "\n",
    "        return {\n",
    "            \"file_name\": path.name,\n",
    "            \"path\": str(path),\n",
    "            \"content_preview\": text_content if text_content.strip() else \"[No readable content]\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "# Create File Reader Agent\n",
    "file_reader_agent = Agent(\n",
    "    name=\"FileReaderAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file classifier. \"\n",
    "        \"1. Always read the file content using `read_contents(file_path)` and summarize it in 1-2 sentences. \"\n",
    "        \"2. Use `load_metadata_tool()` to inspect existing files' descriptions, categories, and tags. \"\n",
    "        \"3. Recommend the most appropriate **category** and **tag** for this file: \"\n",
    "        \"   - The **category** should be a broad, high-level classification (e.g., 'reference_materials', 'novels', 'reports') in snake_case, lowercase, no spaces. \"\n",
    "        \"   - The **tag** should be a more specific subtopic within that category (e.g., 'compiler_design', 'fiction', 'annual_report') in snake_case, lowercase, no spaces. \"\n",
    "        \"   - Reuse an existing category/tag if it already fits the content; create a new one only if necessary. \"\n",
    "        \"4. Only output the recommended category, tag, and 1-2 sentence description. \"\n",
    "        \"   Do not modify metadata.json directly.\"\n",
    "    ),\n",
    "    tools=[read_contents, load_metadata_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "reader_tool = file_reader_agent.as_tool(\n",
    "    tool_name=\"file_reader\",\n",
    "    tool_description=\"Reads a file, generates a short description, and suggests the most appropriate category and tag for it.\"\n",
    ")\n",
    "\n",
    "# Create File Manager Agent\n",
    "file_agent = Agent(\n",
    "    name=\"FileManagerAgent\",\n",
    "    instructions=(\n",
    "        \"You are a file manager agent. \"\n",
    "        \"Your main responsibility is to manage files: add, update, fetch metadata, and delete files. \"\n",
    "        \"\\n\\n\"\n",
    "        \"For file additions: \"\n",
    "        \"- Always keep the original 'name' field exactly as the uploaded filename. \"\n",
    "        \"- By default, call the `file_reader` tool to get the recommended description, category, and tag. \"\n",
    "        \"- If the user explicitly provides a category and/or tag, use those values instead of calling `file_reader` for them. \"\n",
    "        \"- If the user provides a description, use it; otherwise, use the one from `file_reader`. \"\n",
    "        \"- Ensure that category and tag values are stored in snake_case (e.g., 'reference_materials', 'compiler_design'). \"\n",
    "        \"- Never invent categories, tags, or descriptions yourself. \"\n",
    "        \"\\n\\n\"\n",
    "        \"For updating or moving files: \"\n",
    "        \"- Only modify category, tag, or description if explicitly requested by the user. \"\n",
    "        \"- Do not change the filename unless explicitly instructed. \"\n",
    "        \"- Do not reclassify the file with `file_reader` unless the user requests reclassification.\"\n",
    "        \"\\n\\n\"\n",
    "        \"For fetching files: \"\n",
    "        \"- Analyze the metadata's description field to determine relevance. \"\n",
    "        \"- Return files with all metadata fields (name, category, tag, path, description). \"\n",
    "        \"- Never invent or assume content.\"\n",
    "        \"\\n\\n\"\n",
    "        \"Always ground all decisions in metadata and outputs from `file_reader`. \"\n",
    "        \"Never attempt to classify or describe files on your own.\"\n",
    "    ),\n",
    "    tools=[add_file_tool, get_files_tool, delete_files_tool, update_file_tool, reader_tool],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# Web Agent instructions\n",
    "web_instructions = \"\"\"\n",
    "You are an autonomous browsing agent.\n",
    "\n",
    "General Browsing Instructions:\n",
    "- Use ONE browser tab/page for all navigation. Do not open multiple tabs.\n",
    "- When navigating to websites, use the full URL including https:// (e.g., https://youtube.com)\n",
    "- Wait for pages to fully load before taking actions.\n",
    "- Always accept cookies and dismiss pop-ups (e.g., click \"Accept\", \"Not Now\") when prompted.\n",
    "- Close any unnecessary modals, banners, or pop-ups that appear while browsing.\n",
    "\n",
    "Login Instructions:\n",
    "- Use the get_credentials tool to retrieve the correct username and password for the website.\n",
    "- Enter credentials in their respective fields (do not input both in the same box).\n",
    "- After filling out username and password click on login button (Button might be such as Submit, Log in, etc.).\n",
    "- If captcha is present do not click on login button. Call the 'wait_for_user' tool.\n",
    "\n",
    "Website Navigation & Search Instructions:\n",
    "- Navigate the internet autonomously to complete the users instructions.\n",
    "- If one website fails to provide the required content, try alternative approaches or websites until the task is completed.\n",
    "- Follow the users instructions precisely while searching or interacting with the website content.\n",
    "- Be specific with URLs - for YouTube, use https://www.youtube.com\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI Routing Function\n",
    "def get_routing_decision(user_input: str):\n",
    "    \"\"\"Use OpenAI API to determine which agent to route to\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "You are a routing system that decides which specialized agent should handle user requests.\n",
    "\n",
    "Classification Rules:\n",
    "- investigator: Any request involving websites, web browsing, online login, web search, scraping, or internet-based tasks\n",
    "  Examples: \"login vtop\", \"search google\", \"browse youtube\", \"scrape website\", \"check social media\"\n",
    "  \n",
    "- FileManagerAgent: Any request involving local file/folder operations \n",
    "  Examples: \"organize files\", \"delete documents\", \"move photos\", \"search local files\", file uploads\n",
    "\n",
    "Input Processing Rules:\n",
    "FOR INVESTIGATOR:\n",
    "- Extract ONLY the \"User message\" part from the input\n",
    "- Look for the line that starts with \"User message:\" and extract everything after it\n",
    "- Ignore all file metadata, uploaded files info, and system context\n",
    "\n",
    "FOR FileManagerAgent:\n",
    "- Pass the COMPLETE original input including all metadata and context\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the user's request (look for the \"User message:\" part)\n",
    "2. Determine which agent should handle it based on the classification rules\n",
    "3. Return a JSON response with exactly this format:\n",
    "{\n",
    "    \"selected_agent\": \"investigator\" or \"FileManagerAgent\",\n",
    "    \"input\": \"the appropriate input for the selected agent\"\n",
    "}\n",
    "Make sure the User input is present in the input section of the JSON\n",
    "Always return valid JSON. Do not include any other text or explanations outside the JSON.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        routing_response = response.choices[0].message.content.strip()\n",
    "        print(routing_response)\n",
    "        return json.loads(routing_response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in routing decision: {e}\")\n",
    "        # Fallback to file agent for safety\n",
    "        return {\n",
    "            \"selected_agent\": \"FileManagerAgent\",\n",
    "            \"input\": user_input\n",
    "        }\n",
    "\n",
    "# Main Agent Runner Function\n",
    "def run_agent_sync(user_input: str):\n",
    "    \"\"\"Run the agent routing system using OpenAI for routing decisions\"\"\"\n",
    "    from agents import Runner\n",
    "    from agents.items import ToolCallOutputItem\n",
    "    \n",
    "    # Get routing decision from OpenAI\n",
    "    routing_decision = get_routing_decision(user_input)\n",
    "    selected_agent = routing_decision[\"selected_agent\"]\n",
    "    agent_input = routing_decision[\"input\"]\n",
    "    \n",
    "    print(f\"Routing to: {selected_agent}\")  # Debug log\n",
    "    \n",
    "    # Route to appropriate agent based on decision\n",
    "    if selected_agent == \"investigator\":\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            result = loop.run_until_complete(Runner.run(web_agent, agent_input))\n",
    "        except RuntimeError:\n",
    "            result = asyncio.run(Runner.run(web_agent, agent_input))\n",
    "    elif selected_agent == \"FileManagerAgent\":\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            result = loop.run_until_complete(Runner.run(file_agent, agent_input))\n",
    "        except RuntimeError:\n",
    "            result = asyncio.run(Runner.run(file_agent, agent_input))\n",
    "    else:\n",
    "        return f\"Unknown agent: {selected_agent}\", []\n",
    "    \n",
    "    # Extract files to show (existing logic)\n",
    "    files_to_show = []\n",
    "    for item in result.new_items:\n",
    "        if isinstance(item, ToolCallOutputItem) and isinstance(item.output, dict):\n",
    "            if \"files\" in item.output:\n",
    "                files_to_show.extend([Path(f[\"path\"]) for f in item.output[\"files\"] if \"path\" in f])\n",
    "\n",
    "    return result.final_output, files_to_show\n",
    "\n",
    "def fetch_files_for_api(name: str=None, category: str=None, tag: str=None):\n",
    "    \"\"\"Fetches a file asked by the user and sends it back to him.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "    results = []\n",
    "    for entry in metadata:\n",
    "        match = True\n",
    "        if name and entry[\"name\"] != name:\n",
    "            match = False\n",
    "        if category and entry[\"category\"] != category:\n",
    "            match = False\n",
    "        if tag and entry[\"tag\"] != tag:\n",
    "            match = False\n",
    "        if match:\n",
    "            results.append(entry)\n",
    "    return {\n",
    "        \"files\": [\n",
    "            {\"name\": f[\"name\"], \"category\": f[\"category\"], \"tag\": f.get(\"tag\"), \"path\": f[\"path\"]}\n",
    "            for f in results\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Watchdog Setup\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "API_URL = \"http://127.0.0.1:8001/chat\"\n",
    "processed_files = set()\n",
    "\n",
    "def wait_for_file_ready(file_path: Path, timeout=20, poll_interval=0.5):\n",
    "    start_time = time.time()\n",
    "    last_size = -1\n",
    "    while time.time() - start_time < timeout:\n",
    "        if not file_path.exists():\n",
    "            time.sleep(poll_interval)\n",
    "            continue\n",
    "        current_size = file_path.stat().st_size\n",
    "        if current_size == last_size and current_size > 0:\n",
    "            return True\n",
    "        last_size = current_size\n",
    "        time.sleep(poll_interval)\n",
    "    return False\n",
    "\n",
    "class DownloadHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "        file_path = Path(event.src_path)\n",
    "\n",
    "        if file_path.suffix in [\".crdownload\", \".part\", \".tmp\"]:\n",
    "            return\n",
    "\n",
    "        if file_path in processed_files:\n",
    "            return\n",
    "        processed_files.add(file_path)\n",
    "\n",
    "        print(f\"[NEW FILE DETECTED] {file_path}\")\n",
    "\n",
    "        if not wait_for_file_ready(file_path):\n",
    "            print(f\"Warning: File not ready: {file_path}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                files = {\"uploaded_files\": (file_path.name, f)}\n",
    "                response = requests.post(API_URL, files=files)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                resp_json = response.json()\n",
    "                print(f\"[AGENT RESPONSE] {resp_json.get('chat_reply', '')}\")\n",
    "                try:\n",
    "                    file_path.unlink()\n",
    "                    print(f\"Deleted original from Downloads: {file_path}\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Warning: File already deleted: {file_path}\")\n",
    "            else:\n",
    "                print(f\"Warning: API call failed: {response.status_code} {response.text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR running agent] {e}\")\n",
    "\n",
    "def start_download_monitor():\n",
    "    if not DOWNLOADS_DIR.exists():\n",
    "        print(f\"Downloads folder not found: {DOWNLOADS_DIR}\")\n",
    "        return None\n",
    "\n",
    "    event_handler = DownloadHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, str(DOWNLOADS_DIR), recursive=False)\n",
    "    observer.start()\n",
    "    print(f\"Monitoring {DOWNLOADS_DIR} for new downloads...\")\n",
    "\n",
    "    def _keep_alive():\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(2)\n",
    "        except KeyboardInterrupt:\n",
    "            observer.stop()\n",
    "        observer.join()\n",
    "\n",
    "    thread = threading.Thread(target=_keep_alive, daemon=True)\n",
    "    thread.start()\n",
    "    return observer\n",
    "\n",
    "# FastAPI Application\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    # Startup logic\n",
    "    global playwright_server, web_agent\n",
    "    \n",
    "    playwright_server = MCPServerStdio(\n",
    "        params=playwright_params, \n",
    "        client_session_timeout_seconds=60\n",
    "    )\n",
    "    await playwright_server.connect()\n",
    "    \n",
    "    # Create the web_agent with connected MCP server\n",
    "    web_agent = Agent(\n",
    "        name=\"investigator\",\n",
    "        instructions=web_instructions, \n",
    "        model=\"gpt-5-mini\",\n",
    "        mcp_servers=[playwright_server],\n",
    "        tools=[get_credentials, wait_for_user]\n",
    "    )\n",
    "    \n",
    "    yield  # This is where the app runs\n",
    "    \n",
    "    # Shutdown logic\n",
    "    if playwright_server:\n",
    "        await playwright_server.close()\n",
    "\n",
    "app = FastAPI(title=\"File Manager Agent\", lifespan=lifespan)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],       \n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],       \n",
    "    allow_headers=[\"*\"], \n",
    ")\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat_endpoint(\n",
    "    message: Optional[str] = Form(None),\n",
    "    uploaded_files: list[UploadFile] = File(None)\n",
    "):\n",
    "    file_paths = []\n",
    "\n",
    "    # Save uploaded files\n",
    "    if uploaded_files:\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = UPLOADS_DIR / Path(uploaded_file.filename).name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                shutil.copyfileobj(uploaded_file.file, f)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    # Load metadata and include in prompt\n",
    "    metadata = load_metadata()\n",
    "    metadata_json = json.dumps(metadata, indent=2)\n",
    "\n",
    "    user_input = f\"Here is the current file metadata (name, category, tag, description, path):\\n{metadata_json}\\n\\n\"\n",
    "    \n",
    "    if message:\n",
    "        user_input += f\"User message: {message}\\n\"\n",
    "    if file_paths:\n",
    "        user_input += \"Files uploaded:\\n\" + \"\\n\".join(str(p) for p in file_paths)\n",
    "\n",
    "    # Run agent\n",
    "    reply, files_to_show = run_agent_sync(user_input)\n",
    "\n",
    "    # Prepare clickable URLs\n",
    "    files_info = []\n",
    "    for f in files_to_show:\n",
    "        meta = next((m for m in metadata if Path(m[\"path\"]) == f), None)\n",
    "        if meta:\n",
    "            category = meta.get(\"category\")\n",
    "            tag = meta.get(\"tag\")\n",
    "            files_info.append({\n",
    "                \"name\": meta[\"name\"],\n",
    "                \"category\": category,\n",
    "                \"tag\": tag,\n",
    "                \"url\": f\"/download/{meta['name']}?category={category}&tag={tag}\"\n",
    "            })\n",
    "\n",
    "    return JSONResponse({\n",
    "        \"chat_reply\": reply,\n",
    "        \"files\": files_info\n",
    "    })\n",
    "\n",
    "@app.get(\"/files\")\n",
    "def get_files():\n",
    "    try:\n",
    "        with open(METADATA_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return {\"files\": data}\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
    "\n",
    "@app.get(\"/download/{file_name}\")\n",
    "async def download_file(file_name: str, category: str=None, tag: str=None):\n",
    "    files = fetch_files_for_api(name=file_name, category=category, tag=tag).get(\"files\", [])\n",
    "    if not files:\n",
    "        return JSONResponse({\"error\": \"File not found\"}, status_code=404)\n",
    "    \n",
    "    file_path = Path(files[0][\"path\"])\n",
    "    if not file_path.exists():\n",
    "        return JSONResponse({\"error\": \"File not found on disk\"}, status_code=404)\n",
    "\n",
    "    return FileResponse(path=file_path, filename=files[0][\"name\"])\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def home():\n",
    "    return \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>File Manager Agent</title>\n",
    "<style>\n",
    "  body { font-family: Arial, sans-serif; padding: 20px; }\n",
    "  .chat { margin-bottom: 10px; }\n",
    "  .file-links { margin-top: 10px; }\n",
    "  .uploaded-list { margin-top: 10px; color: green; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2> File Manager Agent</h2>\n",
    "\n",
    "<form id=\"chatForm\">\n",
    "  <div class=\"chat\">\n",
    "    <label>Message:</label><br>\n",
    "    <input type=\"text\" id=\"message\" size=\"50\">\n",
    "  </div>\n",
    "  <div class=\"chat\">\n",
    "    <label>Upload Files (optional):</label><br>\n",
    "    <input type=\"file\" id=\"file\" multiple>\n",
    "  </div>\n",
    "  <button type=\"submit\">Send</button>\n",
    "</form>\n",
    "\n",
    "<h3>Uploaded Files:</h3>\n",
    "<div id=\"uploadedFiles\" class=\"uploaded-list\"></div>\n",
    "\n",
    "<h3>Reply:</h3>\n",
    "<div id=\"reply\"></div>\n",
    "\n",
    "<h3>Files:</h3>\n",
    "<div id=\"files\" class=\"file-links\"></div>\n",
    "\n",
    "<script>\n",
    "const form = document.getElementById('chatForm');\n",
    "const fileInput = document.getElementById('file');\n",
    "const uploadedFilesDiv = document.getElementById('uploadedFiles');\n",
    "\n",
    "fileInput.addEventListener('change', () => {\n",
    "  uploadedFilesDiv.innerHTML = '';\n",
    "  if (fileInput.files.length > 0) {\n",
    "    uploadedFilesDiv.innerHTML = `<strong>${fileInput.files.length} file(s) selected:</strong><br>`;\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      uploadedFilesDiv.innerHTML += ` ${fileInput.files[i].name}<br>`;\n",
    "    }\n",
    "  } else {\n",
    "    uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  }\n",
    "});\n",
    "\n",
    "form.addEventListener('submit', async (e) => {\n",
    "  e.preventDefault();\n",
    "\n",
    "  const formData = new FormData();\n",
    "  formData.append('message', document.getElementById('message').value);\n",
    "\n",
    "  if (fileInput.files.length > 0) {\n",
    "    for (let i = 0; i < fileInput.files.length; i++) {\n",
    "      formData.append('uploaded_files', fileInput.files[i]);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const response = await fetch('/chat', {\n",
    "    method: 'POST',\n",
    "    body: formData\n",
    "  });\n",
    "\n",
    "  const data = await response.json();\n",
    "  document.getElementById('reply').innerText = data.chat_reply;\n",
    "\n",
    "  const filesDiv = document.getElementById('files');\n",
    "  filesDiv.innerHTML = '';\n",
    "  if (data.files && data.files.length > 0) {\n",
    "    data.files.forEach(f => {\n",
    "      const link = document.createElement('a');\n",
    "      link.href = f.url;\n",
    "      link.innerText = f.name;\n",
    "      link.target = '_blank';\n",
    "      filesDiv.appendChild(link);\n",
    "      filesDiv.appendChild(document.createElement('br'));\n",
    "    });\n",
    "  }\n",
    "\n",
    "  // Clear file input, uploaded files list, and optionally text\n",
    "  fileInput.value = \"\";\n",
    "  uploadedFilesDiv.innerHTML = 'No files selected';\n",
    "  document.getElementById('message').value = \"\";\n",
    "});\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "\n",
    "# Start monitoring downloads\n",
    "observer = start_download_monitor()\n",
    "\n",
    "# Main execution\n",
    "async def main():\n",
    "    config = uvicorn.Config(app=app, host=\"0.0.0.0\", port=8001, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d967a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
